{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Churn Modelling Prediction Deep Learnign ANN Project\n",
        "Project Introduction: Churn Modeling Prediction with Artificial Neural Networks (ANN)\n",
        "\n",
        "The goal of this deep learning project is to develop a churn modeling prediction system using Artificial Neural Networks (ANN). Churn modeling refers to the analysis of customer behavior to predict the likelihood of customers leaving a service or product. By accurately identifying potential churners, businesses can take proactive measures to retain valuable customers, reduce attrition, and improve overall customer satisfaction.\n",
        "\n",
        "In this project, we will utilize a dataset containing various attributes of customers, including their credit score, geography, gender, age, tenure, balance, number of products, credit card status, activity level, and estimated salary. The dataset also provides information about whether a customer has exited or remained with the company. This data will serve as the foundation for training our ANN model to predict churn.\n",
        "\n",
        "Artificial Neural Networks (ANN) are a class of machine learning algorithms inspired by the structure and functioning of the human brain. ANN models consist of interconnected nodes, or neurons, organized in layers. Each neuron receives input signals, processes them through an activation function, and generates an output signal. By iteratively adjusting the connection weights between neurons, ANNs can learn complex patterns and make accurate predictions.\n",
        "\n",
        "Through this project, we aim to build a robust churn prediction model using an ANN architecture. The trained model will take customer attributes as input and provide a churn prediction as output. This predictive capability will enable businesses to proactively address customer churn by implementing targeted retention strategies, such as personalized offers, tailored communication, or enhanced customer experiences.\n",
        "\n",
        "By leveraging the power of deep learning and ANN techniques, we can provide businesses with valuable insights into customer behavior and improve their ability to retain customers. The project will involve data preprocessing, model training, evaluation, and deployment, enabling organizations to integrate churn prediction into their decision-making processes and enhance customer retention strategies.\n",
        "\n",
        "Let's dive into the implementation details and leverage ANN to build an effective churn prediction model using the provided dataset.\n",
        "\n",
        "Background of the Dataset:\n",
        "\n",
        "The dataset used in this churn modeling prediction project contains information about customers and their behaviors, which will be instrumental in training our Artificial Neural Network (ANN) model. Understanding the background of the dataset is crucial for gaining insights into the context of the problem and interpreting the results accurately.\n",
        "\n",
        "The dataset consists of various attributes for each customer, including:\n",
        "\n",
        "1. RowNumber: Represents the index or row number of the data entry.\n",
        "2. CustomerId: A unique identifier for each customer.\n",
        "3. Surname: The customer's surname or last name.\n",
        "4. CreditScore: The credit score of the customer, indicating their creditworthiness.\n",
        "5. Geography: The country or region to which the customer belongs (e.g., France, Spain).\n",
        "6. Gender: The gender of the customer (e.g., Female, Male).\n",
        "7. Age: The age of the customer.\n",
        "8. Tenure: The number of years the customer has been associated with the company.\n",
        "9. Balance: The account balance of the customer.\n",
        "10. NumOfProducts: The number of products the customer has subscribed to.\n",
        "11. HasCrCard: Indicates whether the customer possesses a credit card (1 for Yes, 0 for No).\n",
        "12. IsActiveMember: Indicates whether the customer is an active member (1 for Yes, 0 for No).\n",
        "13. EstimatedSalary: The estimated salary of the customer.\n",
        "14. Exited: A binary variable indicating whether the customer has exited the company (1 for Yes, 0 for No).\n",
        "\n",
        "This dataset provides a snapshot of customers and their associated attributes, allowing us to analyze patterns and predict churn. The goal is to build an ANN model that can effectively learn from this data and predict the likelihood of a customer churning, based on their characteristics and behavior.\n",
        "\n",
        "By analyzing the relationships between various features, such as credit score, tenure, balance, and customer activity, we can gain insights into the factors that contribute to customer churn. This information can be leveraged by businesses to identify at-risk customers and implement retention strategies aimed at reducing churn rates and improving customer satisfaction.\n",
        "\n",
        "With this dataset, we have a valuable opportunity to explore the power of ANN models in predicting customer churn and ultimately assisting businesses in making data-driven decisions to enhance customer retention.\n",
        "---\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y_aRj_AnPCzT"
      },
      "source": [
        "# 1. Data Gathering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cDouD1cgO-Ir"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7maaVHMQO-NT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uc9JUW2gPOij"
      },
      "source": [
        "#### Data Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DhfWQ759O-Pj",
        "outputId": "4d5a9956-08d1-4160-9a4b-449fd1d6432b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35c6848f-7094-423f-9188-e9332617bf1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35c6848f-7094-423f-9188-e9332617bf1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35c6848f-7094-423f-9188-e9332617bf1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35c6848f-7094-423f-9188-e9332617bf1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8Zbaf3RcO-R2",
        "outputId": "5260f4bd-91e8-477b-dc34-7af230c361cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4283b4a-92b4-4e1a-bf95-987b90bed445\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4283b4a-92b4-4e1a-bf95-987b90bed445')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4283b4a-92b4-4e1a-bf95-987b90bed445 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4283b4a-92b4-4e1a-bf95-987b90bed445');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rxD8Y1ZO-V7",
        "outputId": "41105ad7-7892-4fdd-e674-1eb0dfbcbd63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYSchyywO-Yu",
        "outputId": "c5577016-f3e6-4090-81dc-502880b46ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FjcDVj0dO-f8",
        "outputId": "42b38180-b689-4dbd-cb7d-1ef27b1b94d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3366816-348b-44fe-b298-41dc6ffeb942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>5.012800</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2886.89568</td>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2500.75000</td>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7500.25000</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3366816-348b-44fe-b298-41dc6ffeb942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3366816-348b-44fe-b298-41dc6ffeb942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3366816-348b-44fe-b298-41dc6ffeb942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
              "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
              "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
              "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
              "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
              "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
              "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
              "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
              "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
              "\n",
              "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
              "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
              "mean    76485.889288       1.530200      0.70550        0.515100   \n",
              "std     62397.405202       0.581654      0.45584        0.499797   \n",
              "min         0.000000       1.000000      0.00000        0.000000   \n",
              "25%         0.000000       1.000000      0.00000        0.000000   \n",
              "50%     97198.540000       1.000000      1.00000        1.000000   \n",
              "75%    127644.240000       2.000000      1.00000        1.000000   \n",
              "max    250898.090000       4.000000      1.00000        1.000000   \n",
              "\n",
              "       EstimatedSalary        Exited  \n",
              "count     10000.000000  10000.000000  \n",
              "mean     100090.239881      0.203700  \n",
              "std       57510.492818      0.402769  \n",
              "min          11.580000      0.000000  \n",
              "25%       51002.110000      0.000000  \n",
              "50%      100193.915000      0.000000  \n",
              "75%      149388.247500      0.000000  \n",
              "max      199992.480000      1.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjzjlIcZO-h8",
        "outputId": "c32acd04-0056-4265-f561-b7b02bb9d8ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RowNumber          0\n",
              "CustomerId         0\n",
              "Surname            0\n",
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "Exited             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcaxHrgpPqkz",
        "outputId": "ec1768db-1486-403c-9cbb-fd21f7f074f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "46mKvJduOrcT"
      },
      "source": [
        "# 2. Data Pre-proccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "edNigcYiOpw0",
        "outputId": "189abad3-a115-4550-fed4-110fd85f4c49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0          619    France  Female   42       2       0.00              1   \n",
              "1          608     Spain  Female   41       1   83807.86              1   \n",
              "2          502    France  Female   42       8  159660.80              3   \n",
              "3          699    France  Female   39       1       0.00              2   \n",
              "4          850     Spain  Female   43       2  125510.82              1   \n",
              "\n",
              "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
              "0          1               1        101348.88       1  \n",
              "1          0               1        112542.58       0  \n",
              "2          1               0        113931.57       1  \n",
              "3          0               0         93826.63       0  \n",
              "4          1               1         79084.10       0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop irrelevant columns (e.g., RowNumber, CustomerId, Surname)\n",
        "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MBlLT6E1QNwb"
      },
      "source": [
        "# 3. Feature Engineering  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6AUJhuQXOp07",
        "outputId": "7f1faae0-6316-4083-9db1-3e1e20b9fd3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0          619          0       0   42       2       0.00              1   \n",
              "1          608          2       0   41       1   83807.86              1   \n",
              "2          502          0       0   42       8  159660.80              3   \n",
              "3          699          0       0   39       1       0.00              2   \n",
              "4          850          2       0   43       2  125510.82              1   \n",
              "\n",
              "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
              "0          1               1        101348.88       1  \n",
              "1          0               1        112542.58       0  \n",
              "2          1               0        113931.57       1  \n",
              "3          0               0         93826.63       0  \n",
              "4          1               1         79084.10       0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Encode categorical variables using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['Geography'] = label_encoder.fit_transform(df['Geography'])\n",
        "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lo4-erLIOp27"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "X5u2VfhxOp5C",
        "outputId": "734e2b74-4639-4b19-f7bb-cf317e357f95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows  10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0             619          0       0   42       2       0.00              1   \n",
              "1             608          2       0   41       1   83807.86              1   \n",
              "2             502          0       0   42       8  159660.80              3   \n",
              "3             699          0       0   39       1       0.00              2   \n",
              "4             850          2       0   43       2  125510.82              1   \n",
              "...           ...        ...     ...  ...     ...        ...            ...   \n",
              "9995          771          0       1   39       5       0.00              2   \n",
              "9996          516          0       1   35      10   57369.61              1   \n",
              "9997          709          0       0   36       7       0.00              1   \n",
              "9998          772          1       1   42       3   75075.31              2   \n",
              "9999          792          0       0   28       4  130142.79              1   \n",
              "\n",
              "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
              "0             1               1        101348.88  \n",
              "1             0               1        112542.58  \n",
              "2             1               0        113931.57  \n",
              "3             0               0         93826.63  \n",
              "4             1               1         79084.10  \n",
              "...         ...             ...              ...  \n",
              "9995          1               0         96270.64  \n",
              "9996          1               1        101699.77  \n",
              "9997          0               1         42085.58  \n",
              "9998          1               0         92888.52  \n",
              "9999          1               0         38190.78  \n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZrQS8U3Op7D",
        "outputId": "ea0dee95-9ec1-4ce1-9508-264b28be969c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m1IY33zqRB-j"
      },
      "source": [
        "# 4. Feature Scalling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WjcZSB1uOp8t"
      },
      "outputs": [],
      "source": [
        "# Perform feature scaling on numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3oWzijgRH6z",
        "outputId": "9c12b0f8-cfa5-4e4d-b664-137502e7bd36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.35649971, -0.9055496 ,  0.91324755, ...,  0.64920267,\n",
              "         0.97481699,  1.36766974],\n",
              "       [-0.20389777,  0.30164867,  0.91324755, ...,  0.64920267,\n",
              "         0.97481699,  1.6612541 ],\n",
              "       [-0.96147213,  1.50884694,  0.91324755, ...,  0.64920267,\n",
              "        -1.02583358, -0.25280688],\n",
              "       ...,\n",
              "       [ 0.86500853, -0.9055496 , -1.09499335, ..., -1.54035103,\n",
              "        -1.02583358, -0.1427649 ],\n",
              "       [ 0.15932282, -0.9055496 ,  0.91324755, ...,  0.64920267,\n",
              "        -1.02583358, -0.05082558],\n",
              "       [ 0.47065475,  0.30164867,  0.91324755, ...,  0.64920267,\n",
              "         0.97481699, -0.81456811]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eas4EB6iRH9M",
        "outputId": "a1f7351d-1a08-4789-ed67-2573cb2c66f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.57749609,  0.30164867,  0.91324755, ..., -1.54035103,\n",
              "        -1.02583358, -1.01960511],\n",
              "       [-0.29729735, -0.9055496 ,  0.91324755, ...,  0.64920267,\n",
              "         0.97481699,  0.79888291],\n",
              "       [-0.52560743,  1.50884694, -1.09499335, ...,  0.64920267,\n",
              "        -1.02583358, -0.72797953],\n",
              "       ...,\n",
              "       [ 0.81311987, -0.9055496 , -1.09499335, ...,  0.64920267,\n",
              "        -1.02583358, -1.16591585],\n",
              "       [ 0.41876609, -0.9055496 ,  0.91324755, ...,  0.64920267,\n",
              "        -1.02583358, -0.41163463],\n",
              "       [-0.24540869,  0.30164867,  0.91324755, ...,  0.64920267,\n",
              "         0.97481699,  0.12593183]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_scaled"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "srObz9BKRhNk"
      },
      "source": [
        "# 5. Building the ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHgQw9AnRIIN",
        "outputId": "4d2c8ba3-d246-4707-b903-ab096763b1d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                176       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Initialize the ANN model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "model.add(keras.layers.Dense(units=16, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "# Add additional hidden layers\n",
        "model.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aZvT0Ee0SmiC"
      },
      "source": [
        "# 6. Training the ANN Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcVr8OSTWB9"
      },
      "source": [
        "#### Applying Early Stopping Techniqye to Avoid Overfitting problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G7mLcLTeTUxM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.0001,\n",
        "    patience= 20,\n",
        "    verbose= 1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-YjbbzdRIKl",
        "outputId": "1fb42bbf-802f-4012-cd7a-1d2a3237a848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 2s 3ms/step - loss: 0.6582 - accuracy: 0.6316 - val_loss: 0.5073 - val_accuracy: 0.7994\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7936 - val_loss: 0.4370 - val_accuracy: 0.8037\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8019 - val_loss: 0.4174 - val_accuracy: 0.8263\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8200 - val_loss: 0.4051 - val_accuracy: 0.8294\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8320 - val_loss: 0.3913 - val_accuracy: 0.8413\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8462 - val_loss: 0.3813 - val_accuracy: 0.8444\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8516 - val_loss: 0.3729 - val_accuracy: 0.8462\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8547 - val_loss: 0.3678 - val_accuracy: 0.8506\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8553 - val_loss: 0.3647 - val_accuracy: 0.8525\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8562 - val_loss: 0.3616 - val_accuracy: 0.8544\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8586 - val_loss: 0.3604 - val_accuracy: 0.8537\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8580 - val_loss: 0.3580 - val_accuracy: 0.8550\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8595 - val_loss: 0.3568 - val_accuracy: 0.8500\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8598 - val_loss: 0.3546 - val_accuracy: 0.8537\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8595 - val_loss: 0.3541 - val_accuracy: 0.8537\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8609 - val_loss: 0.3536 - val_accuracy: 0.8531\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8592 - val_loss: 0.3532 - val_accuracy: 0.8562\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8598 - val_loss: 0.3523 - val_accuracy: 0.8544\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8577 - val_loss: 0.3519 - val_accuracy: 0.8562\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8611 - val_loss: 0.3521 - val_accuracy: 0.8550\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8592 - val_loss: 0.3517 - val_accuracy: 0.8537\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8600 - val_loss: 0.3523 - val_accuracy: 0.8519\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8598 - val_loss: 0.3515 - val_accuracy: 0.8562\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8627 - val_loss: 0.3527 - val_accuracy: 0.8531\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8611 - val_loss: 0.3531 - val_accuracy: 0.8562\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8627 - val_loss: 0.3523 - val_accuracy: 0.8512\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8606 - val_loss: 0.3532 - val_accuracy: 0.8537\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8628 - val_loss: 0.3528 - val_accuracy: 0.8562\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8616 - val_loss: 0.3536 - val_accuracy: 0.8550\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8617 - val_loss: 0.3530 - val_accuracy: 0.8556\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8633 - val_loss: 0.3533 - val_accuracy: 0.8556\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8617 - val_loss: 0.3533 - val_accuracy: 0.8556\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8633 - val_loss: 0.3526 - val_accuracy: 0.8562\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8628 - val_loss: 0.3531 - val_accuracy: 0.8550\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8625 - val_loss: 0.3535 - val_accuracy: 0.8550\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8630 - val_loss: 0.3527 - val_accuracy: 0.8550\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8641 - val_loss: 0.3526 - val_accuracy: 0.8562\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8645 - val_loss: 0.3529 - val_accuracy: 0.8550\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8627 - val_loss: 0.3534 - val_accuracy: 0.8544\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8619 - val_loss: 0.3542 - val_accuracy: 0.8544\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8634 - val_loss: 0.3528 - val_accuracy: 0.8556\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8641 - val_loss: 0.3524 - val_accuracy: 0.8519\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8639 - val_loss: 0.3533 - val_accuracy: 0.8537\n",
            "Epoch 43: early stopping\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8615\n",
            "Test Loss: 0.33916544914245605\n",
            "Test Accuracy: 0.8615000247955322\n"
          ]
        }
      ],
      "source": [
        "# Train the ANN model\n",
        "model_history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=100, validation_split=0.2, callbacks = early_stopping)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmsbnr_PRIMf",
        "outputId": "1a22284c-5526-42fd-9910-751d42033e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ],
      "source": [
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UMB1VmfJRIOk",
        "outputId": "457bd59a-c5a3-4497-da7f-544399b3e364"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "25ak56NoWH7t",
        "outputId": "a3e4e916-12de-4ef5-b56e-e843b8623aed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0qWj0XW8hG"
      },
      "source": [
        "# 7. Make predictions on the testing set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pFxeXPVXAim",
        "outputId": "3ba2296f-9d3f-47e5-b963-99d147549900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "[0. 0. 0. ... 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2SrQ1HdfWkcd"
      },
      "source": [
        "# 8. Evaluating the ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJtaASnnWID-",
        "outputId": "735df1ba-0257-4220-f547-0a3c92138e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8615\n",
            "Precision: 0.7457627118644068\n",
            "Recall: 0.44783715012722647\n",
            "F1-Score: 0.5596184419713831\n",
            "Confusion Matrix:\n",
            "[[1547   60]\n",
            " [ 217  176]]\n"
          ]
        }
      ],
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "MRks0y9nWIIp",
        "outputId": "229aabde-e2d8-434e-c4a6-3ad9937a3ff2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate ROC curve and calculate AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(auc))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o7SRI-XxYYav"
      },
      "source": [
        "# 9. Model Optimization\n",
        "### Hyper-perameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkEoODMMWILa",
        "outputId": "38e8b3cf-4646-42df-c7c3-2c4a1c67faf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-0b8b29ee78a1>:22: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8598\n",
            "Epoch 26/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8607\n",
            "Epoch 27/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8645\n",
            "Epoch 28/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8616\n",
            "Epoch 29/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8635\n",
            "Epoch 30/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8641\n",
            "Epoch 31/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8616\n",
            "Epoch 32/170\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8633\n",
            "Epoch 33/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8646\n",
            "Epoch 34/170\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8628\n",
            "Epoch 35/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8622\n",
            "Epoch 36/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8645\n",
            "Epoch 37/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8639\n",
            "Epoch 38/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8616\n",
            "Epoch 39/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8633\n",
            "Epoch 40/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8631\n",
            "Epoch 41/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8615\n",
            "Epoch 42/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8635\n",
            "Epoch 43/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8633\n",
            "Epoch 44/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 45/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8628\n",
            "Epoch 46/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8650\n",
            "Epoch 47/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8637\n",
            "Epoch 48/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8646\n",
            "Epoch 49/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8650\n",
            "Epoch 50/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8643\n",
            "Epoch 51/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8645\n",
            "Epoch 52/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8643\n",
            "Epoch 53/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8631\n",
            "Epoch 54/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8652\n",
            "Epoch 55/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8654\n",
            "Epoch 56/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8671\n",
            "Epoch 57/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8671\n",
            "Epoch 58/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8671\n",
            "Epoch 59/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8660\n",
            "Epoch 60/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8663\n",
            "Epoch 61/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8686\n",
            "Epoch 62/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8648\n",
            "Epoch 63/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8682\n",
            "Epoch 64/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8678\n",
            "Epoch 65/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8673\n",
            "Epoch 66/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8669\n",
            "Epoch 67/170\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8667\n",
            "Epoch 68/170\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8686\n",
            "Epoch 69/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8667\n",
            "Epoch 70/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8710\n",
            "Epoch 71/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8671\n",
            "Epoch 72/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8686\n",
            "Epoch 73/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8695\n",
            "Epoch 74/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8705\n",
            "Epoch 75/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8703\n",
            "Epoch 76/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8688\n",
            "Epoch 77/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8697\n",
            "Epoch 78/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8695\n",
            "Epoch 79/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8716\n",
            "Epoch 80/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8691\n",
            "Epoch 81/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8705\n",
            "Epoch 82/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8678\n",
            "Epoch 83/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8695\n",
            "Epoch 84/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8699\n",
            "Epoch 85/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8714\n",
            "Epoch 86/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8705\n",
            "Epoch 87/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8699\n",
            "Epoch 88/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8703\n",
            "Epoch 89/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8710\n",
            "Epoch 90/170\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8725\n",
            "Epoch 91/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8695\n",
            "Epoch 92/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8735\n",
            "Epoch 93/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8733\n",
            "Epoch 94/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8740\n",
            "Epoch 95/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8729\n",
            "Epoch 96/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8738\n",
            "Epoch 97/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8718\n",
            "Epoch 98/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8731\n",
            "Epoch 99/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8718\n",
            "Epoch 100/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8714\n",
            "Epoch 101/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8721\n",
            "Epoch 102/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8735\n",
            "Epoch 103/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8720\n",
            "Epoch 104/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8742\n",
            "Epoch 105/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8708\n",
            "Epoch 106/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8727\n",
            "Epoch 107/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8735\n",
            "Epoch 108/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8733\n",
            "Epoch 109/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8716\n",
            "Epoch 110/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8731\n",
            "Epoch 111/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8774\n",
            "Epoch 112/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8740\n",
            "Epoch 113/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8748\n",
            "Epoch 114/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8736\n",
            "Epoch 115/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8736\n",
            "Epoch 116/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.8740\n",
            "Epoch 117/170\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8750\n",
            "Epoch 118/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8725\n",
            "Epoch 119/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8740\n",
            "Epoch 120/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8748\n",
            "Epoch 121/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8759\n",
            "Epoch 122/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8748\n",
            "Epoch 123/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8744\n",
            "Epoch 124/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8720\n",
            "Epoch 125/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8736\n",
            "Epoch 126/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8766\n",
            "Epoch 127/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8763\n",
            "Epoch 128/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8753\n",
            "Epoch 129/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8735\n",
            "Epoch 130/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8753\n",
            "Epoch 131/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8759\n",
            "Epoch 132/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8757\n",
            "Epoch 133/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8753\n",
            "Epoch 134/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8744\n",
            "Epoch 135/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8766\n",
            "Epoch 136/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8787\n",
            "Epoch 137/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8750\n",
            "Epoch 138/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8772\n",
            "Epoch 139/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8766\n",
            "Epoch 140/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.8776\n",
            "Epoch 141/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8766\n",
            "Epoch 142/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8768\n",
            "Epoch 143/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8770\n",
            "Epoch 144/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8759\n",
            "Epoch 145/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8776\n",
            "Epoch 146/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8795\n",
            "Epoch 147/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.8770\n",
            "Epoch 148/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8789\n",
            "Epoch 149/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8795\n",
            "Epoch 150/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8791\n",
            "Epoch 151/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8780\n",
            "Epoch 152/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8766\n",
            "Epoch 153/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8798\n",
            "Epoch 154/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8789\n",
            "Epoch 155/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8804\n",
            "Epoch 156/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8791\n",
            "Epoch 157/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8796\n",
            "Epoch 158/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8787\n",
            "Epoch 159/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8787\n",
            "Epoch 160/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.8776\n",
            "Epoch 161/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8757\n",
            "Epoch 162/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.8808\n",
            "Epoch 163/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8798\n",
            "Epoch 164/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8795\n",
            "Epoch 165/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8787\n",
            "Epoch 166/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8806\n",
            "Epoch 167/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8789\n",
            "Epoch 168/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8806\n",
            "Epoch 169/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8810\n",
            "Epoch 170/170\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8780\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.7917\n",
            "Epoch 2/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8048\n",
            "Epoch 3/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8204\n",
            "Epoch 4/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8271\n",
            "Epoch 5/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8350\n",
            "Epoch 6/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8365\n",
            "Epoch 7/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8431\n",
            "Epoch 8/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8438\n",
            "Epoch 9/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8481\n",
            "Epoch 10/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8485\n",
            "Epoch 11/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8506\n",
            "Epoch 12/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8528\n",
            "Epoch 13/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8537\n",
            "Epoch 14/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8556\n",
            "Epoch 15/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8562\n",
            "Epoch 16/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8545\n",
            "Epoch 17/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8566\n",
            "Epoch 18/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8556\n",
            "Epoch 19/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8567\n",
            "Epoch 20/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8582\n",
            "Epoch 21/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8584\n",
            "Epoch 22/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8579\n",
            "Epoch 23/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8577\n",
            "Epoch 24/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8588\n",
            "Epoch 25/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8588\n",
            "Epoch 26/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8612\n",
            "Epoch 27/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8616\n",
            "Epoch 28/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8594\n",
            "Epoch 29/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8607\n",
            "Epoch 30/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8622\n",
            "Epoch 31/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8622\n",
            "Epoch 32/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8611\n",
            "Epoch 33/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8631\n",
            "Epoch 34/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8620\n",
            "Epoch 35/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8624\n",
            "Epoch 36/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8622\n",
            "Epoch 37/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8639\n",
            "Epoch 38/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8639\n",
            "Epoch 39/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8654\n",
            "Epoch 40/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8656\n",
            "Epoch 41/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8663\n",
            "Epoch 42/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8641\n",
            "Epoch 43/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8674\n",
            "Epoch 44/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8637\n",
            "Epoch 45/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8663\n",
            "Epoch 46/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8661\n",
            "Epoch 47/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8657\n",
            "Epoch 48/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8657\n",
            "Epoch 49/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8657\n",
            "Epoch 50/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8656\n",
            "Epoch 51/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8669\n",
            "Epoch 52/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8682\n",
            "Epoch 53/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8693\n",
            "Epoch 54/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8687\n",
            "Epoch 55/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8665\n",
            "Epoch 56/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8682\n",
            "Epoch 57/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8671\n",
            "Epoch 58/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8687\n",
            "Epoch 59/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8678\n",
            "Epoch 60/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8671\n",
            "Epoch 61/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8693\n",
            "Epoch 62/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8697\n",
            "Epoch 63/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8689\n",
            "Epoch 64/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8676\n",
            "Epoch 65/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8710\n",
            "Epoch 66/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8714\n",
            "Epoch 67/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8689\n",
            "Epoch 68/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8678\n",
            "Epoch 69/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8686\n",
            "Epoch 70/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8706\n",
            "Epoch 71/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.8734\n",
            "Epoch 72/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8723\n",
            "Epoch 73/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8691\n",
            "Epoch 74/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8712\n",
            "Epoch 75/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8702\n",
            "Epoch 76/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8717\n",
            "Epoch 77/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8704\n",
            "Epoch 78/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8721\n",
            "Epoch 79/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8706\n",
            "Epoch 80/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8716\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7922\n",
            "Epoch 2/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8108\n",
            "Epoch 3/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8176\n",
            "Epoch 4/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8219\n",
            "Epoch 5/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8260\n",
            "Epoch 6/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8322\n",
            "Epoch 7/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8359\n",
            "Epoch 8/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8410\n",
            "Epoch 9/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8427\n",
            "Epoch 10/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8451\n",
            "Epoch 11/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8479\n",
            "Epoch 12/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8494\n",
            "Epoch 13/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8511\n",
            "Epoch 14/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8522\n",
            "Epoch 15/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8543\n",
            "Epoch 16/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8556\n",
            "Epoch 17/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8575\n",
            "Epoch 18/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8567\n",
            "Epoch 19/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8569\n",
            "Epoch 20/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8594\n",
            "Epoch 21/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8590\n",
            "Epoch 22/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8590\n",
            "Epoch 23/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8584\n",
            "Epoch 24/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8599\n",
            "Epoch 25/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8618\n",
            "Epoch 26/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8611\n",
            "Epoch 27/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8624\n",
            "Epoch 28/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8629\n",
            "Epoch 29/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8618\n",
            "Epoch 30/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8622\n",
            "Epoch 31/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8646\n",
            "Epoch 32/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8612\n",
            "Epoch 33/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8620\n",
            "Epoch 34/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8637\n",
            "Epoch 35/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8631\n",
            "Epoch 36/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8648\n",
            "Epoch 37/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8631\n",
            "Epoch 38/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8637\n",
            "Epoch 39/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8637\n",
            "Epoch 40/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8648\n",
            "Epoch 41/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8648\n",
            "Epoch 42/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8648\n",
            "Epoch 43/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8657\n",
            "Epoch 44/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 45/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8644\n",
            "Epoch 46/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8656\n",
            "Epoch 47/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8659\n",
            "Epoch 48/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8657\n",
            "Epoch 49/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8665\n",
            "Epoch 50/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8687\n",
            "Epoch 51/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8686\n",
            "Epoch 52/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8667\n",
            "Epoch 53/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8676\n",
            "Epoch 54/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8676\n",
            "Epoch 55/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8682\n",
            "Epoch 56/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8714\n",
            "Epoch 57/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8678\n",
            "Epoch 58/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8669\n",
            "Epoch 59/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8674\n",
            "Epoch 60/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8680\n",
            "Epoch 61/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8699\n",
            "Epoch 62/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8702\n",
            "Epoch 63/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8708\n",
            "Epoch 64/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.8687\n",
            "Epoch 65/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8717\n",
            "Epoch 66/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8712\n",
            "Epoch 67/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8721\n",
            "Epoch 68/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8708\n",
            "Epoch 69/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8712\n",
            "Epoch 70/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8719\n",
            "Epoch 71/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8719\n",
            "Epoch 72/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8708\n",
            "Epoch 73/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8710\n",
            "Epoch 74/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8719\n",
            "Epoch 75/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8712\n",
            "Epoch 76/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8727\n",
            "Epoch 77/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8716\n",
            "Epoch 78/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8729\n",
            "Epoch 79/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8706\n",
            "Epoch 80/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8723\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 0.5260 - accuracy: 0.7814\n",
            "Epoch 2/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7996\n",
            "Epoch 3/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8148\n",
            "Epoch 4/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8253\n",
            "Epoch 5/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8375\n",
            "Epoch 6/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8440\n",
            "Epoch 7/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8487\n",
            "Epoch 8/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8510\n",
            "Epoch 9/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8560\n",
            "Epoch 10/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8586\n",
            "Epoch 11/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8577\n",
            "Epoch 12/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8566\n",
            "Epoch 13/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8585\n",
            "Epoch 14/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8594\n",
            "Epoch 15/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8592\n",
            "Epoch 16/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8586\n",
            "Epoch 17/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8588\n",
            "Epoch 18/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8579\n",
            "Epoch 19/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8588\n",
            "Epoch 20/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8590\n",
            "Epoch 21/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8592\n",
            "Epoch 22/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8585\n",
            "Epoch 23/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8592\n",
            "Epoch 24/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8628\n",
            "Epoch 25/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8609\n",
            "Epoch 26/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8609\n",
            "Epoch 27/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8618\n",
            "Epoch 28/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8628\n",
            "Epoch 29/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8637\n",
            "Epoch 30/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8631\n",
            "Epoch 31/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8628\n",
            "Epoch 32/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8633\n",
            "Epoch 33/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8645\n",
            "Epoch 34/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8645\n",
            "Epoch 35/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8665\n",
            "Epoch 36/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8660\n",
            "Epoch 37/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8660\n",
            "Epoch 38/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8661\n",
            "Epoch 39/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8656\n",
            "Epoch 40/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8663\n",
            "Epoch 41/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8665\n",
            "Epoch 42/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8650\n",
            "Epoch 43/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8680\n",
            "Epoch 44/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8693\n",
            "Epoch 45/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8678\n",
            "Epoch 46/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8676\n",
            "Epoch 47/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8705\n",
            "Epoch 48/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8671\n",
            "Epoch 49/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8691\n",
            "Epoch 50/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8705\n",
            "Epoch 51/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8697\n",
            "Epoch 52/80\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8690\n",
            "Epoch 53/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8706\n",
            "Epoch 54/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8695\n",
            "Epoch 55/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8714\n",
            "Epoch 56/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8712\n",
            "Epoch 57/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8716\n",
            "Epoch 58/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8708\n",
            "Epoch 59/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8731\n",
            "Epoch 60/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8716\n",
            "Epoch 61/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3105 - accuracy: 0.8733\n",
            "Epoch 62/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8725\n",
            "Epoch 63/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8733\n",
            "Epoch 64/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8742\n",
            "Epoch 65/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8735\n",
            "Epoch 66/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8740\n",
            "Epoch 67/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8740\n",
            "Epoch 68/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8733\n",
            "Epoch 69/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8757\n",
            "Epoch 70/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8755\n",
            "Epoch 71/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.8744\n",
            "Epoch 72/80\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3045 - accuracy: 0.8761\n",
            "Epoch 73/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8759\n",
            "Epoch 74/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8759\n",
            "Epoch 75/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8746\n",
            "Epoch 76/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8772\n",
            "Epoch 77/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8768\n",
            "Epoch 78/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8765\n",
            "Epoch 79/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8763\n",
            "Epoch 80/80\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8765\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/96\n",
            "141/141 [==============================] - 2s 4ms/step - loss: 0.5185 - accuracy: 0.7568\n",
            "Epoch 2/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4276 - accuracy: 0.8119\n",
            "Epoch 3/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4157 - accuracy: 0.8168\n",
            "Epoch 4/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4021 - accuracy: 0.8251\n",
            "Epoch 5/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.8322\n",
            "Epoch 6/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8401\n",
            "Epoch 7/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8455\n",
            "Epoch 8/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3635 - accuracy: 0.8500\n",
            "Epoch 9/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3571 - accuracy: 0.8517\n",
            "Epoch 10/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8552\n",
            "Epoch 11/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8551\n",
            "Epoch 12/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.8569\n",
            "Epoch 13/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3464 - accuracy: 0.8592\n",
            "Epoch 14/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.8569\n",
            "Epoch 15/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3433 - accuracy: 0.8571\n",
            "Epoch 16/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8556\n",
            "Epoch 17/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8586\n",
            "Epoch 18/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3409 - accuracy: 0.8560\n",
            "Epoch 19/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8582\n",
            "Epoch 20/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8560\n",
            "Epoch 21/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8577\n",
            "Epoch 22/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8581\n",
            "Epoch 23/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8612\n",
            "Epoch 24/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8584\n",
            "Epoch 25/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8605\n",
            "Epoch 26/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8599\n",
            "Epoch 27/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3316 - accuracy: 0.8605\n",
            "Epoch 28/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8611\n",
            "Epoch 29/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8616\n",
            "Epoch 30/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3276 - accuracy: 0.8599\n",
            "Epoch 31/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3277 - accuracy: 0.8624\n",
            "Epoch 32/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3272 - accuracy: 0.8622\n",
            "Epoch 33/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.8644\n",
            "Epoch 34/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8618\n",
            "Epoch 35/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.8618\n",
            "Epoch 36/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3230 - accuracy: 0.8627\n",
            "Epoch 37/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.8646\n",
            "Epoch 38/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.8629\n",
            "Epoch 39/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8671\n",
            "Epoch 40/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.8661\n",
            "Epoch 41/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3179 - accuracy: 0.8669\n",
            "Epoch 42/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8672\n",
            "Epoch 43/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.8671\n",
            "Epoch 44/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8661\n",
            "Epoch 45/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8671\n",
            "Epoch 46/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3134 - accuracy: 0.8686\n",
            "Epoch 47/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3122 - accuracy: 0.8669\n",
            "Epoch 48/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8686\n",
            "Epoch 49/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3125 - accuracy: 0.8684\n",
            "Epoch 50/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3119 - accuracy: 0.8710\n",
            "Epoch 51/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3090 - accuracy: 0.8693\n",
            "Epoch 52/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3093 - accuracy: 0.8732\n",
            "Epoch 53/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3082 - accuracy: 0.8723\n",
            "Epoch 54/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3081 - accuracy: 0.8712\n",
            "Epoch 55/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.8708\n",
            "Epoch 56/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3063 - accuracy: 0.8719\n",
            "Epoch 57/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.8717\n",
            "Epoch 58/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3049 - accuracy: 0.8747\n",
            "Epoch 59/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3046 - accuracy: 0.8721\n",
            "Epoch 60/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3039 - accuracy: 0.8736\n",
            "Epoch 61/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8740\n",
            "Epoch 62/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3019 - accuracy: 0.8740\n",
            "Epoch 63/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8751\n",
            "Epoch 64/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3025 - accuracy: 0.8732\n",
            "Epoch 65/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3007 - accuracy: 0.8738\n",
            "Epoch 66/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3000 - accuracy: 0.8742\n",
            "Epoch 67/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2997 - accuracy: 0.8746\n",
            "Epoch 68/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2991 - accuracy: 0.8729\n",
            "Epoch 69/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2974 - accuracy: 0.8742\n",
            "Epoch 70/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.8764\n",
            "Epoch 71/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2973 - accuracy: 0.8744\n",
            "Epoch 72/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2966 - accuracy: 0.8738\n",
            "Epoch 73/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2960 - accuracy: 0.8755\n",
            "Epoch 74/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8768\n",
            "Epoch 75/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2940 - accuracy: 0.8762\n",
            "Epoch 76/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.8762\n",
            "Epoch 77/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.8761\n",
            "Epoch 78/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.8736\n",
            "Epoch 79/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2926 - accuracy: 0.8768\n",
            "Epoch 80/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2917 - accuracy: 0.8764\n",
            "Epoch 81/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.8772\n",
            "Epoch 82/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2908 - accuracy: 0.8781\n",
            "Epoch 83/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.8753\n",
            "Epoch 84/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2891 - accuracy: 0.8802\n",
            "Epoch 85/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2880 - accuracy: 0.8783\n",
            "Epoch 86/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.8800\n",
            "Epoch 87/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.8777\n",
            "Epoch 88/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2862 - accuracy: 0.8794\n",
            "Epoch 89/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8777\n",
            "Epoch 90/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.8809\n",
            "Epoch 91/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2843 - accuracy: 0.8807\n",
            "Epoch 92/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2838 - accuracy: 0.8806\n",
            "Epoch 93/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.8779\n",
            "Epoch 94/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2824 - accuracy: 0.8802\n",
            "Epoch 95/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.8806\n",
            "Epoch 96/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2816 - accuracy: 0.8804\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/96\n",
            "141/141 [==============================] - 2s 4ms/step - loss: 0.5372 - accuracy: 0.7437\n",
            "Epoch 2/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.8076\n",
            "Epoch 3/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4246 - accuracy: 0.8153\n",
            "Epoch 4/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4080 - accuracy: 0.8224\n",
            "Epoch 5/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8365\n",
            "Epoch 6/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8455\n",
            "Epoch 7/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8507\n",
            "Epoch 8/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8507\n",
            "Epoch 9/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3589 - accuracy: 0.8532\n",
            "Epoch 10/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8541\n",
            "Epoch 11/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8552\n",
            "Epoch 12/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8551\n",
            "Epoch 13/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8577\n",
            "Epoch 14/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8584\n",
            "Epoch 15/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8571\n",
            "Epoch 16/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8592\n",
            "Epoch 17/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.8603\n",
            "Epoch 18/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8612\n",
            "Epoch 19/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8603\n",
            "Epoch 20/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.8620\n",
            "Epoch 21/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8620\n",
            "Epoch 22/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8637\n",
            "Epoch 23/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8624\n",
            "Epoch 24/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8622\n",
            "Epoch 25/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8642\n",
            "Epoch 26/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8635\n",
            "Epoch 27/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 28/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.8652\n",
            "Epoch 29/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 30/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8657\n",
            "Epoch 31/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8652\n",
            "Epoch 32/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8648\n",
            "Epoch 33/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8684\n",
            "Epoch 34/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8661\n",
            "Epoch 35/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.8667\n",
            "Epoch 36/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8699\n",
            "Epoch 37/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8686\n",
            "Epoch 38/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8693\n",
            "Epoch 39/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8676\n",
            "Epoch 40/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3198 - accuracy: 0.8676\n",
            "Epoch 41/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8701\n",
            "Epoch 42/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8686\n",
            "Epoch 43/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8697\n",
            "Epoch 44/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3176 - accuracy: 0.8708\n",
            "Epoch 45/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8714\n",
            "Epoch 46/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.8699\n",
            "Epoch 47/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8710\n",
            "Epoch 48/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8684\n",
            "Epoch 49/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3136 - accuracy: 0.8695\n",
            "Epoch 50/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8706\n",
            "Epoch 51/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8719\n",
            "Epoch 52/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3117 - accuracy: 0.8725\n",
            "Epoch 53/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8725\n",
            "Epoch 54/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3114 - accuracy: 0.8714\n",
            "Epoch 55/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3107 - accuracy: 0.8716\n",
            "Epoch 56/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8725\n",
            "Epoch 57/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.8721\n",
            "Epoch 58/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8708\n",
            "Epoch 59/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3097 - accuracy: 0.8727\n",
            "Epoch 60/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3080 - accuracy: 0.8706\n",
            "Epoch 61/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3079 - accuracy: 0.8708\n",
            "Epoch 62/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3067 - accuracy: 0.8740\n",
            "Epoch 63/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3065 - accuracy: 0.8689\n",
            "Epoch 64/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.8731\n",
            "Epoch 65/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3050 - accuracy: 0.8751\n",
            "Epoch 66/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3038 - accuracy: 0.8744\n",
            "Epoch 67/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.8738\n",
            "Epoch 68/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3034 - accuracy: 0.8746\n",
            "Epoch 69/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.8746\n",
            "Epoch 70/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.8738\n",
            "Epoch 71/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.8753\n",
            "Epoch 72/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.8774\n",
            "Epoch 73/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3016 - accuracy: 0.8747\n",
            "Epoch 74/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.8762\n",
            "Epoch 75/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8770\n",
            "Epoch 76/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2989 - accuracy: 0.8731\n",
            "Epoch 77/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2991 - accuracy: 0.8757\n",
            "Epoch 78/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.8774\n",
            "Epoch 79/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2977 - accuracy: 0.8772\n",
            "Epoch 80/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2979 - accuracy: 0.8764\n",
            "Epoch 81/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.8772\n",
            "Epoch 82/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2954 - accuracy: 0.8764\n",
            "Epoch 83/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2947 - accuracy: 0.8755\n",
            "Epoch 84/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2949 - accuracy: 0.8762\n",
            "Epoch 85/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.8791\n",
            "Epoch 86/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.8794\n",
            "Epoch 87/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2940 - accuracy: 0.8785\n",
            "Epoch 88/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.8774\n",
            "Epoch 89/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2917 - accuracy: 0.8806\n",
            "Epoch 90/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2913 - accuracy: 0.8783\n",
            "Epoch 91/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.8815\n",
            "Epoch 92/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2894 - accuracy: 0.8794\n",
            "Epoch 93/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2897 - accuracy: 0.8789\n",
            "Epoch 94/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2881 - accuracy: 0.8772\n",
            "Epoch 95/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.8794\n",
            "Epoch 96/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2887 - accuracy: 0.8798\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/96\n",
            "141/141 [==============================] - 2s 4ms/step - loss: 0.5083 - accuracy: 0.7672\n",
            "Epoch 2/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4205 - accuracy: 0.8097\n",
            "Epoch 3/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.8223\n",
            "Epoch 4/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8339\n",
            "Epoch 5/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8433\n",
            "Epoch 6/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8510\n",
            "Epoch 7/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8553\n",
            "Epoch 8/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8553\n",
            "Epoch 9/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8570\n",
            "Epoch 10/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8566\n",
            "Epoch 11/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3458 - accuracy: 0.8575\n",
            "Epoch 12/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8590\n",
            "Epoch 13/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8592\n",
            "Epoch 14/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8616\n",
            "Epoch 15/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3381 - accuracy: 0.8630\n",
            "Epoch 16/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3377 - accuracy: 0.8624\n",
            "Epoch 17/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8624\n",
            "Epoch 18/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8631\n",
            "Epoch 19/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.8622\n",
            "Epoch 20/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8656\n",
            "Epoch 21/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8661\n",
            "Epoch 22/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8633\n",
            "Epoch 23/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.8665\n",
            "Epoch 24/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8686\n",
            "Epoch 25/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8658\n",
            "Epoch 26/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8671\n",
            "Epoch 27/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8658\n",
            "Epoch 28/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.8695\n",
            "Epoch 29/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3212 - accuracy: 0.8733\n",
            "Epoch 30/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3217 - accuracy: 0.8708\n",
            "Epoch 31/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8686\n",
            "Epoch 32/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8695\n",
            "Epoch 33/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3196 - accuracy: 0.8735\n",
            "Epoch 34/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8716\n",
            "Epoch 35/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3180 - accuracy: 0.8701\n",
            "Epoch 36/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8725\n",
            "Epoch 37/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8695\n",
            "Epoch 38/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.8723\n",
            "Epoch 39/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3152 - accuracy: 0.8716\n",
            "Epoch 40/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.8742\n",
            "Epoch 41/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3146 - accuracy: 0.8727\n",
            "Epoch 42/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3117 - accuracy: 0.8746\n",
            "Epoch 43/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3141 - accuracy: 0.8729\n",
            "Epoch 44/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3132 - accuracy: 0.8729\n",
            "Epoch 45/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8727\n",
            "Epoch 46/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.8751\n",
            "Epoch 47/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.8748\n",
            "Epoch 48/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3105 - accuracy: 0.8725\n",
            "Epoch 49/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.8740\n",
            "Epoch 50/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8757\n",
            "Epoch 51/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8755\n",
            "Epoch 52/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3084 - accuracy: 0.8765\n",
            "Epoch 53/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3079 - accuracy: 0.8751\n",
            "Epoch 54/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3077 - accuracy: 0.8746\n",
            "Epoch 55/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3061 - accuracy: 0.8750\n",
            "Epoch 56/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3063 - accuracy: 0.8761\n",
            "Epoch 57/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3060 - accuracy: 0.8781\n",
            "Epoch 58/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3060 - accuracy: 0.8763\n",
            "Epoch 59/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3052 - accuracy: 0.8738\n",
            "Epoch 60/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3050 - accuracy: 0.8791\n",
            "Epoch 61/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3036 - accuracy: 0.8778\n",
            "Epoch 62/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3030 - accuracy: 0.8755\n",
            "Epoch 63/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8772\n",
            "Epoch 64/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3028 - accuracy: 0.8759\n",
            "Epoch 65/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8781\n",
            "Epoch 66/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3014 - accuracy: 0.8795\n",
            "Epoch 67/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3019 - accuracy: 0.8757\n",
            "Epoch 68/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3000 - accuracy: 0.8796\n",
            "Epoch 69/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3011 - accuracy: 0.8778\n",
            "Epoch 70/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.3006 - accuracy: 0.8791\n",
            "Epoch 71/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.8768\n",
            "Epoch 72/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2985 - accuracy: 0.8815\n",
            "Epoch 73/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8787\n",
            "Epoch 74/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.8795\n",
            "Epoch 75/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2968 - accuracy: 0.8789\n",
            "Epoch 76/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2977 - accuracy: 0.8765\n",
            "Epoch 77/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8804\n",
            "Epoch 78/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8813\n",
            "Epoch 79/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2950 - accuracy: 0.8796\n",
            "Epoch 80/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.8811\n",
            "Epoch 81/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.8825\n",
            "Epoch 82/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2938 - accuracy: 0.8796\n",
            "Epoch 83/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2944 - accuracy: 0.8806\n",
            "Epoch 84/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2938 - accuracy: 0.8796\n",
            "Epoch 85/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2923 - accuracy: 0.8815\n",
            "Epoch 86/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2914 - accuracy: 0.8823\n",
            "Epoch 87/96\n",
            "141/141 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8841\n",
            "Epoch 88/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2914 - accuracy: 0.8819\n",
            "Epoch 89/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2905 - accuracy: 0.8832\n",
            "Epoch 90/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2898 - accuracy: 0.8828\n",
            "Epoch 91/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2892 - accuracy: 0.8819\n",
            "Epoch 92/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2887 - accuracy: 0.8838\n",
            "Epoch 93/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8856\n",
            "Epoch 94/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2875 - accuracy: 0.8836\n",
            "Epoch 95/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2872 - accuracy: 0.8838\n",
            "Epoch 96/96\n",
            "141/141 [==============================] - 1s 4ms/step - loss: 0.2867 - accuracy: 0.8830\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/160\n",
            "72/72 [==============================] - 1s 4ms/step - loss: 0.5724 - accuracy: 0.7309\n",
            "Epoch 2/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8033\n",
            "Epoch 3/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8099\n",
            "Epoch 4/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8112\n",
            "Epoch 5/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8174\n",
            "Epoch 6/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8232\n",
            "Epoch 7/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8262\n",
            "Epoch 8/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8303\n",
            "Epoch 9/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8380\n",
            "Epoch 10/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8412\n",
            "Epoch 11/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8436\n",
            "Epoch 12/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8440\n",
            "Epoch 13/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8477\n",
            "Epoch 14/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8481\n",
            "Epoch 15/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8506\n",
            "Epoch 16/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8519\n",
            "Epoch 17/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8552\n",
            "Epoch 18/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8539\n",
            "Epoch 19/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8541\n",
            "Epoch 20/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8547\n",
            "Epoch 21/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8558\n",
            "Epoch 22/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8549\n",
            "Epoch 23/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8554\n",
            "Epoch 24/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8536\n",
            "Epoch 25/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8552\n",
            "Epoch 26/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8564\n",
            "Epoch 27/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8564\n",
            "Epoch 28/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8562\n",
            "Epoch 29/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8562\n",
            "Epoch 30/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8573\n",
            "Epoch 31/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8556\n",
            "Epoch 32/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8577\n",
            "Epoch 33/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8549\n",
            "Epoch 34/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8556\n",
            "Epoch 35/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8581\n",
            "Epoch 36/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8581\n",
            "Epoch 37/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8566\n",
            "Epoch 38/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8584\n",
            "Epoch 39/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8594\n",
            "Epoch 40/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8579\n",
            "Epoch 41/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8596\n",
            "Epoch 42/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8586\n",
            "Epoch 43/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8586\n",
            "Epoch 44/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8618\n",
            "Epoch 45/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8611\n",
            "Epoch 46/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8607\n",
            "Epoch 47/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8614\n",
            "Epoch 48/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8618\n",
            "Epoch 49/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8618\n",
            "Epoch 50/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8620\n",
            "Epoch 51/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8635\n",
            "Epoch 52/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8627\n",
            "Epoch 53/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8611\n",
            "Epoch 54/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8654\n",
            "Epoch 55/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8642\n",
            "Epoch 56/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8635\n",
            "Epoch 57/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8652\n",
            "Epoch 58/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8629\n",
            "Epoch 59/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8642\n",
            "Epoch 60/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.8631\n",
            "Epoch 61/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8646\n",
            "Epoch 62/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8671\n",
            "Epoch 63/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.8646\n",
            "Epoch 64/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8671\n",
            "Epoch 65/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8641\n",
            "Epoch 66/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8669\n",
            "Epoch 67/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8657\n",
            "Epoch 68/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8639\n",
            "Epoch 69/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8674\n",
            "Epoch 70/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.8663\n",
            "Epoch 71/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8691\n",
            "Epoch 72/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8644\n",
            "Epoch 73/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8665\n",
            "Epoch 74/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8672\n",
            "Epoch 75/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8699\n",
            "Epoch 76/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8672\n",
            "Epoch 77/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8667\n",
            "Epoch 78/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8672\n",
            "Epoch 79/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8684\n",
            "Epoch 80/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8671\n",
            "Epoch 81/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8680\n",
            "Epoch 82/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8652\n",
            "Epoch 83/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8701\n",
            "Epoch 84/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8686\n",
            "Epoch 85/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8671\n",
            "Epoch 86/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8680\n",
            "Epoch 87/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.8663\n",
            "Epoch 88/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8682\n",
            "Epoch 89/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8678\n",
            "Epoch 90/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8689\n",
            "Epoch 91/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8669\n",
            "Epoch 92/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8680\n",
            "Epoch 93/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8680\n",
            "Epoch 94/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8691\n",
            "Epoch 95/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8706\n",
            "Epoch 96/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8669\n",
            "Epoch 97/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8714\n",
            "Epoch 98/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8684\n",
            "Epoch 99/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8697\n",
            "Epoch 100/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8699\n",
            "Epoch 101/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8680\n",
            "Epoch 102/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8710\n",
            "Epoch 103/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.8672\n",
            "Epoch 104/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8714\n",
            "Epoch 105/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.8680\n",
            "Epoch 106/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.8716\n",
            "Epoch 107/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.8702\n",
            "Epoch 108/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8723\n",
            "Epoch 109/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8684\n",
            "Epoch 110/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8689\n",
            "Epoch 111/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8710\n",
            "Epoch 112/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8699\n",
            "Epoch 113/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8689\n",
            "Epoch 114/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8680\n",
            "Epoch 115/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8695\n",
            "Epoch 116/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8678\n",
            "Epoch 117/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8701\n",
            "Epoch 118/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8682\n",
            "Epoch 119/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8714\n",
            "Epoch 120/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8708\n",
            "Epoch 121/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8708\n",
            "Epoch 122/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8695\n",
            "Epoch 123/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8729\n",
            "Epoch 124/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8732\n",
            "Epoch 125/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8727\n",
            "Epoch 126/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8699\n",
            "Epoch 127/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8701\n",
            "Epoch 128/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8719\n",
            "Epoch 129/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8702\n",
            "Epoch 130/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8704\n",
            "Epoch 131/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8719\n",
            "Epoch 132/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8697\n",
            "Epoch 133/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8753\n",
            "Epoch 134/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8716\n",
            "Epoch 135/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8714\n",
            "Epoch 136/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8702\n",
            "Epoch 137/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8717\n",
            "Epoch 138/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8717\n",
            "Epoch 139/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8719\n",
            "Epoch 140/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.8719\n",
            "Epoch 141/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8723\n",
            "Epoch 142/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8702\n",
            "Epoch 143/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8717\n",
            "Epoch 144/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8710\n",
            "Epoch 145/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2983 - accuracy: 0.8710\n",
            "Epoch 146/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.8729\n",
            "Epoch 147/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2987 - accuracy: 0.8747\n",
            "Epoch 148/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8746\n",
            "Epoch 149/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2977 - accuracy: 0.8746\n",
            "Epoch 150/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.8742\n",
            "Epoch 151/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8764\n",
            "Epoch 152/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.8747\n",
            "Epoch 153/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8770\n",
            "Epoch 154/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8749\n",
            "Epoch 155/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8753\n",
            "Epoch 156/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.8759\n",
            "Epoch 157/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8740\n",
            "Epoch 158/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8740\n",
            "Epoch 159/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8742\n",
            "Epoch 160/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8768\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/160\n",
            "72/72 [==============================] - 1s 4ms/step - loss: 0.5716 - accuracy: 0.7148\n",
            "Epoch 2/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8001\n",
            "Epoch 3/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8089\n",
            "Epoch 4/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8119\n",
            "Epoch 5/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8174\n",
            "Epoch 6/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8194\n",
            "Epoch 7/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8202\n",
            "Epoch 8/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8260\n",
            "Epoch 9/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8296\n",
            "Epoch 10/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8322\n",
            "Epoch 11/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8378\n",
            "Epoch 12/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8389\n",
            "Epoch 13/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8432\n",
            "Epoch 14/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8453\n",
            "Epoch 15/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8500\n",
            "Epoch 16/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8483\n",
            "Epoch 17/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8504\n",
            "Epoch 18/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8539\n",
            "Epoch 19/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8536\n",
            "Epoch 20/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8564\n",
            "Epoch 21/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8558\n",
            "Epoch 22/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8573\n",
            "Epoch 23/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8592\n",
            "Epoch 24/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8588\n",
            "Epoch 25/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8582\n",
            "Epoch 26/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8605\n",
            "Epoch 27/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8575\n",
            "Epoch 28/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8609\n",
            "Epoch 29/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3429 - accuracy: 0.8624\n",
            "Epoch 30/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8609\n",
            "Epoch 31/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8622\n",
            "Epoch 32/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8590\n",
            "Epoch 33/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8612\n",
            "Epoch 34/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8620\n",
            "Epoch 35/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8616\n",
            "Epoch 36/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8631\n",
            "Epoch 37/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8611\n",
            "Epoch 38/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8627\n",
            "Epoch 39/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8614\n",
            "Epoch 40/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8631\n",
            "Epoch 41/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8652\n",
            "Epoch 42/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8627\n",
            "Epoch 43/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8616\n",
            "Epoch 44/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8641\n",
            "Epoch 45/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8620\n",
            "Epoch 46/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8656\n",
            "Epoch 47/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8650\n",
            "Epoch 48/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8626\n",
            "Epoch 49/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 50/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 51/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8671\n",
            "Epoch 52/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8656\n",
            "Epoch 53/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8646\n",
            "Epoch 54/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8656\n",
            "Epoch 55/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8661\n",
            "Epoch 56/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8667\n",
            "Epoch 57/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8663\n",
            "Epoch 58/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8659\n",
            "Epoch 59/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8661\n",
            "Epoch 60/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8663\n",
            "Epoch 61/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8659\n",
            "Epoch 62/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8659\n",
            "Epoch 63/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8671\n",
            "Epoch 64/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8663\n",
            "Epoch 65/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8691\n",
            "Epoch 66/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8659\n",
            "Epoch 67/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8671\n",
            "Epoch 68/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3208 - accuracy: 0.8682\n",
            "Epoch 69/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8680\n",
            "Epoch 70/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8678\n",
            "Epoch 71/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8665\n",
            "Epoch 72/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.8648\n",
            "Epoch 73/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8672\n",
            "Epoch 74/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8671\n",
            "Epoch 75/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8691\n",
            "Epoch 76/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8648\n",
            "Epoch 77/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8693\n",
            "Epoch 78/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8674\n",
            "Epoch 79/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8693\n",
            "Epoch 80/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8676\n",
            "Epoch 81/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8676\n",
            "Epoch 82/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8680\n",
            "Epoch 83/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8691\n",
            "Epoch 84/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8691\n",
            "Epoch 85/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8697\n",
            "Epoch 86/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8676\n",
            "Epoch 87/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8693\n",
            "Epoch 88/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8686\n",
            "Epoch 89/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8704\n",
            "Epoch 90/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8680\n",
            "Epoch 91/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8682\n",
            "Epoch 92/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8691\n",
            "Epoch 93/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8701\n",
            "Epoch 94/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8699\n",
            "Epoch 95/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8691\n",
            "Epoch 96/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8680\n",
            "Epoch 97/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8701\n",
            "Epoch 98/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8704\n",
            "Epoch 99/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8687\n",
            "Epoch 100/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8687\n",
            "Epoch 101/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8689\n",
            "Epoch 102/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8693\n",
            "Epoch 103/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8714\n",
            "Epoch 104/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8669\n",
            "Epoch 105/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3112 - accuracy: 0.8710\n",
            "Epoch 106/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8729\n",
            "Epoch 107/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8693\n",
            "Epoch 108/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8712\n",
            "Epoch 109/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8684\n",
            "Epoch 110/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3096 - accuracy: 0.8697\n",
            "Epoch 111/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8723\n",
            "Epoch 112/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8701\n",
            "Epoch 113/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3091 - accuracy: 0.8723\n",
            "Epoch 114/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8691\n",
            "Epoch 115/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.8708\n",
            "Epoch 116/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8727\n",
            "Epoch 117/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8686\n",
            "Epoch 118/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8695\n",
            "Epoch 119/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8725\n",
            "Epoch 120/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8719\n",
            "Epoch 121/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8725\n",
            "Epoch 122/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8727\n",
            "Epoch 123/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8716\n",
            "Epoch 124/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8704\n",
            "Epoch 125/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8725\n",
            "Epoch 126/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.8723\n",
            "Epoch 127/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8732\n",
            "Epoch 128/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8721\n",
            "Epoch 129/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8738\n",
            "Epoch 130/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8710\n",
            "Epoch 131/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8699\n",
            "Epoch 132/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8732\n",
            "Epoch 133/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8712\n",
            "Epoch 134/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8729\n",
            "Epoch 135/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8732\n",
            "Epoch 136/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8732\n",
            "Epoch 137/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8727\n",
            "Epoch 138/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8734\n",
            "Epoch 139/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8734\n",
            "Epoch 140/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8731\n",
            "Epoch 141/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8734\n",
            "Epoch 142/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8740\n",
            "Epoch 143/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8740\n",
            "Epoch 144/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8736\n",
            "Epoch 145/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8734\n",
            "Epoch 146/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8738\n",
            "Epoch 147/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8729\n",
            "Epoch 148/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8764\n",
            "Epoch 149/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8736\n",
            "Epoch 150/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8744\n",
            "Epoch 151/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.8732\n",
            "Epoch 152/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8731\n",
            "Epoch 153/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.8723\n",
            "Epoch 154/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.8744\n",
            "Epoch 155/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.8729\n",
            "Epoch 156/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2992 - accuracy: 0.8734\n",
            "Epoch 157/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2983 - accuracy: 0.8740\n",
            "Epoch 158/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8759\n",
            "Epoch 159/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8736\n",
            "Epoch 160/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8736\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/160\n",
            "72/72 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6974\n",
            "Epoch 2/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7988\n",
            "Epoch 3/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8078\n",
            "Epoch 4/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8140\n",
            "Epoch 5/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8196\n",
            "Epoch 6/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8294\n",
            "Epoch 7/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8339\n",
            "Epoch 8/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8420\n",
            "Epoch 9/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8442\n",
            "Epoch 10/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8493\n",
            "Epoch 11/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8498\n",
            "Epoch 12/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8534\n",
            "Epoch 13/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8553\n",
            "Epoch 14/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8562\n",
            "Epoch 15/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3521 - accuracy: 0.8564\n",
            "Epoch 16/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8577\n",
            "Epoch 17/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8564\n",
            "Epoch 18/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8556\n",
            "Epoch 19/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8558\n",
            "Epoch 20/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8579\n",
            "Epoch 21/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8577\n",
            "Epoch 22/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8594\n",
            "Epoch 23/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8600\n",
            "Epoch 24/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8586\n",
            "Epoch 25/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8603\n",
            "Epoch 26/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8613\n",
            "Epoch 27/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8626\n",
            "Epoch 28/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8605\n",
            "Epoch 29/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8630\n",
            "Epoch 30/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8620\n",
            "Epoch 31/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8628\n",
            "Epoch 32/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8635\n",
            "Epoch 33/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8637\n",
            "Epoch 34/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8645\n",
            "Epoch 35/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8630\n",
            "Epoch 36/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8661\n",
            "Epoch 37/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8663\n",
            "Epoch 38/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8628\n",
            "Epoch 39/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8690\n",
            "Epoch 40/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8656\n",
            "Epoch 41/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8669\n",
            "Epoch 42/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8667\n",
            "Epoch 43/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8671\n",
            "Epoch 44/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8673\n",
            "Epoch 45/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8695\n",
            "Epoch 46/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8671\n",
            "Epoch 47/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8671\n",
            "Epoch 48/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8701\n",
            "Epoch 49/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.8710\n",
            "Epoch 50/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8695\n",
            "Epoch 51/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8660\n",
            "Epoch 52/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8682\n",
            "Epoch 53/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3193 - accuracy: 0.8701\n",
            "Epoch 54/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8686\n",
            "Epoch 55/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.8680\n",
            "Epoch 56/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8693\n",
            "Epoch 57/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8684\n",
            "Epoch 58/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8693\n",
            "Epoch 59/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8690\n",
            "Epoch 60/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8705\n",
            "Epoch 61/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8695\n",
            "Epoch 62/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8710\n",
            "Epoch 63/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8695\n",
            "Epoch 64/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.8706\n",
            "Epoch 65/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8678\n",
            "Epoch 66/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8699\n",
            "Epoch 67/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8697\n",
            "Epoch 68/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8725\n",
            "Epoch 69/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8705\n",
            "Epoch 70/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8699\n",
            "Epoch 71/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8710\n",
            "Epoch 72/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8729\n",
            "Epoch 73/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8727\n",
            "Epoch 74/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8675\n",
            "Epoch 75/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8682\n",
            "Epoch 76/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8721\n",
            "Epoch 77/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8714\n",
            "Epoch 78/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8731\n",
            "Epoch 79/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8693\n",
            "Epoch 80/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8693\n",
            "Epoch 81/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8691\n",
            "Epoch 82/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8706\n",
            "Epoch 83/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8712\n",
            "Epoch 84/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8712\n",
            "Epoch 85/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8740\n",
            "Epoch 86/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8695\n",
            "Epoch 87/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8705\n",
            "Epoch 88/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8725\n",
            "Epoch 89/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8701\n",
            "Epoch 90/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8742\n",
            "Epoch 91/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8736\n",
            "Epoch 92/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8729\n",
            "Epoch 93/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8714\n",
            "Epoch 94/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8701\n",
            "Epoch 95/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3066 - accuracy: 0.8733\n",
            "Epoch 96/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8712\n",
            "Epoch 97/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8720\n",
            "Epoch 98/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3050 - accuracy: 0.8755\n",
            "Epoch 99/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3054 - accuracy: 0.8750\n",
            "Epoch 100/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8727\n",
            "Epoch 101/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8744\n",
            "Epoch 102/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8725\n",
            "Epoch 103/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8738\n",
            "Epoch 104/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8733\n",
            "Epoch 105/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8753\n",
            "Epoch 106/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8731\n",
            "Epoch 107/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8725\n",
            "Epoch 108/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3033 - accuracy: 0.8723\n",
            "Epoch 109/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8740\n",
            "Epoch 110/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8755\n",
            "Epoch 111/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8706\n",
            "Epoch 112/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8736\n",
            "Epoch 113/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8753\n",
            "Epoch 114/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8750\n",
            "Epoch 115/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8750\n",
            "Epoch 116/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8753\n",
            "Epoch 117/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8748\n",
            "Epoch 118/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8746\n",
            "Epoch 119/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8755\n",
            "Epoch 120/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8750\n",
            "Epoch 121/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8736\n",
            "Epoch 122/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8765\n",
            "Epoch 123/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8725\n",
            "Epoch 124/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8761\n",
            "Epoch 125/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8755\n",
            "Epoch 126/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.8753\n",
            "Epoch 127/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.8759\n",
            "Epoch 128/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8768\n",
            "Epoch 129/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8761\n",
            "Epoch 130/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8766\n",
            "Epoch 131/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8763\n",
            "Epoch 132/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8763\n",
            "Epoch 133/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8753\n",
            "Epoch 134/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2969 - accuracy: 0.8766\n",
            "Epoch 135/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.8751\n",
            "Epoch 136/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8759\n",
            "Epoch 137/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8757\n",
            "Epoch 138/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2963 - accuracy: 0.8765\n",
            "Epoch 139/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8761\n",
            "Epoch 140/160\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.8748\n",
            "Epoch 141/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.8776\n",
            "Epoch 142/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8757\n",
            "Epoch 143/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8772\n",
            "Epoch 144/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8783\n",
            "Epoch 145/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8778\n",
            "Epoch 146/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8776\n",
            "Epoch 147/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2943 - accuracy: 0.8766\n",
            "Epoch 148/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8761\n",
            "Epoch 149/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.8748\n",
            "Epoch 150/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8776\n",
            "Epoch 151/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.8791\n",
            "Epoch 152/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8748\n",
            "Epoch 153/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.8763\n",
            "Epoch 154/160\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.8770\n",
            "Epoch 155/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8778\n",
            "Epoch 156/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8798\n",
            "Epoch 157/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8776\n",
            "Epoch 158/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8789\n",
            "Epoch 159/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8772\n",
            "Epoch 160/160\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8772\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/121\n",
            "54/54 [==============================] - 1s 4ms/step - loss: 0.5863 - accuracy: 0.7020\n",
            "Epoch 2/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7995\n",
            "Epoch 3/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8065\n",
            "Epoch 4/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8072\n",
            "Epoch 5/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8138\n",
            "Epoch 6/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8140\n",
            "Epoch 7/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8207\n",
            "Epoch 8/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8277\n",
            "Epoch 9/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8329\n",
            "Epoch 10/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8365\n",
            "Epoch 11/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8406\n",
            "Epoch 12/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8451\n",
            "Epoch 13/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8459\n",
            "Epoch 14/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8477\n",
            "Epoch 15/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8453\n",
            "Epoch 16/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8521\n",
            "Epoch 17/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8502\n",
            "Epoch 18/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8519\n",
            "Epoch 19/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8513\n",
            "Epoch 20/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8528\n",
            "Epoch 21/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8521\n",
            "Epoch 22/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8556\n",
            "Epoch 23/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8536\n",
            "Epoch 24/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8560\n",
            "Epoch 25/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8564\n",
            "Epoch 26/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8556\n",
            "Epoch 27/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8564\n",
            "Epoch 28/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8560\n",
            "Epoch 29/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8562\n",
            "Epoch 30/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8551\n",
            "Epoch 31/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8558\n",
            "Epoch 32/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8564\n",
            "Epoch 33/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8596\n",
            "Epoch 34/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8567\n",
            "Epoch 35/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8584\n",
            "Epoch 36/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8579\n",
            "Epoch 37/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8594\n",
            "Epoch 38/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8584\n",
            "Epoch 39/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.8605\n",
            "Epoch 40/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8566\n",
            "Epoch 41/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8582\n",
            "Epoch 42/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8611\n",
            "Epoch 43/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8577\n",
            "Epoch 44/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8599\n",
            "Epoch 45/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8564\n",
            "Epoch 46/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8588\n",
            "Epoch 47/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8605\n",
            "Epoch 48/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8584\n",
            "Epoch 49/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8594\n",
            "Epoch 50/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8605\n",
            "Epoch 51/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8605\n",
            "Epoch 52/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8590\n",
            "Epoch 53/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8641\n",
            "Epoch 54/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8616\n",
            "Epoch 55/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8601\n",
            "Epoch 56/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8624\n",
            "Epoch 57/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8611\n",
            "Epoch 58/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8618\n",
            "Epoch 59/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8609\n",
            "Epoch 60/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.8641\n",
            "Epoch 61/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8624\n",
            "Epoch 62/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8639\n",
            "Epoch 63/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.8627\n",
            "Epoch 64/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8650\n",
            "Epoch 65/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8641\n",
            "Epoch 66/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8650\n",
            "Epoch 67/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8654\n",
            "Epoch 68/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8633\n",
            "Epoch 69/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8656\n",
            "Epoch 70/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8665\n",
            "Epoch 71/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8652\n",
            "Epoch 72/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8652\n",
            "Epoch 73/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8657\n",
            "Epoch 74/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8659\n",
            "Epoch 75/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8682\n",
            "Epoch 76/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8641\n",
            "Epoch 77/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8663\n",
            "Epoch 78/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8672\n",
            "Epoch 79/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3171 - accuracy: 0.8680\n",
            "Epoch 80/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8686\n",
            "Epoch 81/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.8686\n",
            "Epoch 82/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8656\n",
            "Epoch 83/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8682\n",
            "Epoch 84/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8691\n",
            "Epoch 85/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8663\n",
            "Epoch 86/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8678\n",
            "Epoch 87/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8680\n",
            "Epoch 88/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8674\n",
            "Epoch 89/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8686\n",
            "Epoch 90/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8687\n",
            "Epoch 91/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8689\n",
            "Epoch 92/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3133 - accuracy: 0.8687\n",
            "Epoch 93/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8686\n",
            "Epoch 94/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8689\n",
            "Epoch 95/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8710\n",
            "Epoch 96/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3113 - accuracy: 0.8716\n",
            "Epoch 97/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.8680\n",
            "Epoch 98/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3111 - accuracy: 0.8714\n",
            "Epoch 99/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8710\n",
            "Epoch 100/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.8699\n",
            "Epoch 101/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8721\n",
            "Epoch 102/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8716\n",
            "Epoch 103/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8701\n",
            "Epoch 104/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8693\n",
            "Epoch 105/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8723\n",
            "Epoch 106/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8702\n",
            "Epoch 107/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8702\n",
            "Epoch 108/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3075 - accuracy: 0.8717\n",
            "Epoch 109/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8712\n",
            "Epoch 110/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8710\n",
            "Epoch 111/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8729\n",
            "Epoch 112/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8721\n",
            "Epoch 113/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8721\n",
            "Epoch 114/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8729\n",
            "Epoch 115/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8731\n",
            "Epoch 116/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8755\n",
            "Epoch 117/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8717\n",
            "Epoch 118/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8731\n",
            "Epoch 119/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8716\n",
            "Epoch 120/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8729\n",
            "Epoch 121/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.8725\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/121\n",
            "54/54 [==============================] - 1s 5ms/step - loss: 0.5818 - accuracy: 0.7285\n",
            "Epoch 2/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7995\n",
            "Epoch 3/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8121\n",
            "Epoch 4/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8161\n",
            "Epoch 5/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8191\n",
            "Epoch 6/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8245\n",
            "Epoch 7/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8282\n",
            "Epoch 8/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8318\n",
            "Epoch 9/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8352\n",
            "Epoch 10/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8397\n",
            "Epoch 11/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8410\n",
            "Epoch 12/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8470\n",
            "Epoch 13/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8476\n",
            "Epoch 14/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8489\n",
            "Epoch 15/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8509\n",
            "Epoch 16/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8519\n",
            "Epoch 17/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8526\n",
            "Epoch 18/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8534\n",
            "Epoch 19/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8539\n",
            "Epoch 20/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8564\n",
            "Epoch 21/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8541\n",
            "Epoch 22/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8584\n",
            "Epoch 23/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8577\n",
            "Epoch 24/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8567\n",
            "Epoch 25/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.8596\n",
            "Epoch 26/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8596\n",
            "Epoch 27/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8584\n",
            "Epoch 28/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8590\n",
            "Epoch 29/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8605\n",
            "Epoch 30/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8599\n",
            "Epoch 31/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8605\n",
            "Epoch 32/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8629\n",
            "Epoch 33/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8626\n",
            "Epoch 34/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8612\n",
            "Epoch 35/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8594\n",
            "Epoch 36/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8601\n",
            "Epoch 37/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8603\n",
            "Epoch 38/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8637\n",
            "Epoch 39/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8603\n",
            "Epoch 40/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8612\n",
            "Epoch 41/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3386 - accuracy: 0.8618\n",
            "Epoch 42/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8620\n",
            "Epoch 43/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8609\n",
            "Epoch 44/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8607\n",
            "Epoch 45/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8626\n",
            "Epoch 46/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8620\n",
            "Epoch 47/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8641\n",
            "Epoch 48/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8637\n",
            "Epoch 49/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8642\n",
            "Epoch 50/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8629\n",
            "Epoch 51/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8622\n",
            "Epoch 52/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8639\n",
            "Epoch 53/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8631\n",
            "Epoch 54/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8637\n",
            "Epoch 55/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8650\n",
            "Epoch 56/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8652\n",
            "Epoch 57/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8656\n",
            "Epoch 58/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8654\n",
            "Epoch 59/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 60/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8641\n",
            "Epoch 61/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8663\n",
            "Epoch 62/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8656\n",
            "Epoch 63/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8659\n",
            "Epoch 64/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8659\n",
            "Epoch 65/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8687\n",
            "Epoch 66/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8650\n",
            "Epoch 67/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8652\n",
            "Epoch 68/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8648\n",
            "Epoch 69/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8687\n",
            "Epoch 70/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8665\n",
            "Epoch 71/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8672\n",
            "Epoch 72/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8656\n",
            "Epoch 73/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8678\n",
            "Epoch 74/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8678\n",
            "Epoch 75/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8678\n",
            "Epoch 76/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8667\n",
            "Epoch 77/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8667\n",
            "Epoch 78/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8687\n",
            "Epoch 79/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8682\n",
            "Epoch 80/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.8686\n",
            "Epoch 81/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8680\n",
            "Epoch 82/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8695\n",
            "Epoch 83/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8697\n",
            "Epoch 84/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8682\n",
            "Epoch 85/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8684\n",
            "Epoch 86/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3181 - accuracy: 0.8714\n",
            "Epoch 87/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8682\n",
            "Epoch 88/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3170 - accuracy: 0.8689\n",
            "Epoch 89/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8689\n",
            "Epoch 90/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8680\n",
            "Epoch 91/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8712\n",
            "Epoch 92/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8695\n",
            "Epoch 93/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8691\n",
            "Epoch 94/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8710\n",
            "Epoch 95/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8706\n",
            "Epoch 96/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8682\n",
            "Epoch 97/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8708\n",
            "Epoch 98/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8684\n",
            "Epoch 99/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8710\n",
            "Epoch 100/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8684\n",
            "Epoch 101/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8721\n",
            "Epoch 102/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8695\n",
            "Epoch 103/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8676\n",
            "Epoch 104/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8676\n",
            "Epoch 105/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8697\n",
            "Epoch 106/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8710\n",
            "Epoch 107/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8691\n",
            "Epoch 108/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8701\n",
            "Epoch 109/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8701\n",
            "Epoch 110/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8695\n",
            "Epoch 111/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8708\n",
            "Epoch 112/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8699\n",
            "Epoch 113/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8695\n",
            "Epoch 114/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8682\n",
            "Epoch 115/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8701\n",
            "Epoch 116/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8716\n",
            "Epoch 117/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8717\n",
            "Epoch 118/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8697\n",
            "Epoch 119/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8704\n",
            "Epoch 120/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8695\n",
            "Epoch 121/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8714\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/121\n",
            "54/54 [==============================] - 1s 4ms/step - loss: 0.5883 - accuracy: 0.7064\n",
            "Epoch 2/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7942\n",
            "Epoch 3/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8060\n",
            "Epoch 4/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8086\n",
            "Epoch 5/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8165\n",
            "Epoch 6/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8195\n",
            "Epoch 7/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8277\n",
            "Epoch 8/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8305\n",
            "Epoch 9/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8341\n",
            "Epoch 10/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8401\n",
            "Epoch 11/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8446\n",
            "Epoch 12/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8448\n",
            "Epoch 13/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8513\n",
            "Epoch 14/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8515\n",
            "Epoch 15/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8536\n",
            "Epoch 16/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8549\n",
            "Epoch 17/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8547\n",
            "Epoch 18/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8573\n",
            "Epoch 19/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8573\n",
            "Epoch 20/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8586\n",
            "Epoch 21/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8585\n",
            "Epoch 22/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8603\n",
            "Epoch 23/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8613\n",
            "Epoch 24/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8616\n",
            "Epoch 25/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8624\n",
            "Epoch 26/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8611\n",
            "Epoch 27/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8633\n",
            "Epoch 28/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8601\n",
            "Epoch 29/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8620\n",
            "Epoch 30/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8622\n",
            "Epoch 31/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8645\n",
            "Epoch 32/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8618\n",
            "Epoch 33/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8645\n",
            "Epoch 34/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8635\n",
            "Epoch 35/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8646\n",
            "Epoch 36/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8631\n",
            "Epoch 37/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8648\n",
            "Epoch 38/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8646\n",
            "Epoch 39/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8665\n",
            "Epoch 40/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8656\n",
            "Epoch 41/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8652\n",
            "Epoch 42/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8675\n",
            "Epoch 43/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8660\n",
            "Epoch 44/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8665\n",
            "Epoch 45/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8671\n",
            "Epoch 46/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8654\n",
            "Epoch 47/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8667\n",
            "Epoch 48/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8680\n",
            "Epoch 49/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8676\n",
            "Epoch 50/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8684\n",
            "Epoch 51/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8686\n",
            "Epoch 52/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8699\n",
            "Epoch 53/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8690\n",
            "Epoch 54/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8695\n",
            "Epoch 55/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8688\n",
            "Epoch 56/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8703\n",
            "Epoch 57/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8701\n",
            "Epoch 58/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8729\n",
            "Epoch 59/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8720\n",
            "Epoch 60/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8716\n",
            "Epoch 61/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8718\n",
            "Epoch 62/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8725\n",
            "Epoch 63/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8708\n",
            "Epoch 64/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8731\n",
            "Epoch 65/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8736\n",
            "Epoch 66/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8714\n",
            "Epoch 67/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8716\n",
            "Epoch 68/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8706\n",
            "Epoch 69/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8725\n",
            "Epoch 70/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3131 - accuracy: 0.8755\n",
            "Epoch 71/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8727\n",
            "Epoch 72/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8723\n",
            "Epoch 73/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8742\n",
            "Epoch 74/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8766\n",
            "Epoch 75/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8744\n",
            "Epoch 76/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3112 - accuracy: 0.8712\n",
            "Epoch 77/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8742\n",
            "Epoch 78/121\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.3106 - accuracy: 0.8731\n",
            "Epoch 79/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8761\n",
            "Epoch 80/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8751\n",
            "Epoch 81/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8761\n",
            "Epoch 82/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8750\n",
            "Epoch 83/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8746\n",
            "Epoch 84/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8733\n",
            "Epoch 85/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8736\n",
            "Epoch 86/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8738\n",
            "Epoch 87/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8763\n",
            "Epoch 88/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8757\n",
            "Epoch 89/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8757\n",
            "Epoch 90/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8766\n",
            "Epoch 91/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8753\n",
            "Epoch 92/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8753\n",
            "Epoch 93/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8744\n",
            "Epoch 94/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8753\n",
            "Epoch 95/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8763\n",
            "Epoch 96/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8772\n",
            "Epoch 97/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8759\n",
            "Epoch 98/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8774\n",
            "Epoch 99/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8785\n",
            "Epoch 100/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8763\n",
            "Epoch 101/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8781\n",
            "Epoch 102/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8774\n",
            "Epoch 103/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8748\n",
            "Epoch 104/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8783\n",
            "Epoch 105/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8776\n",
            "Epoch 106/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8759\n",
            "Epoch 107/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8763\n",
            "Epoch 108/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8770\n",
            "Epoch 109/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8780\n",
            "Epoch 110/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8785\n",
            "Epoch 111/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8787\n",
            "Epoch 112/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8759\n",
            "Epoch 113/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8774\n",
            "Epoch 114/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8795\n",
            "Epoch 115/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8763\n",
            "Epoch 116/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.8780\n",
            "Epoch 117/121\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8770\n",
            "Epoch 118/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8768\n",
            "Epoch 119/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8789\n",
            "Epoch 120/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8761\n",
            "Epoch 121/121\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8802\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "42/42 [==============================] - 2s 6ms/step - loss: 0.6897 - accuracy: 0.5691\n",
            "Epoch 2/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.5970 - accuracy: 0.6983\n",
            "Epoch 3/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7682\n",
            "Epoch 4/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7930\n",
            "Epoch 5/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8033\n",
            "Epoch 6/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8076\n",
            "Epoch 7/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.8091\n",
            "Epoch 8/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.8119\n",
            "Epoch 9/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8110\n",
            "Epoch 10/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8136\n",
            "Epoch 11/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8144\n",
            "Epoch 12/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8161\n",
            "Epoch 13/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8168\n",
            "Epoch 14/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8202\n",
            "Epoch 15/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8211\n",
            "Epoch 16/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8215\n",
            "Epoch 17/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8243\n",
            "Epoch 18/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8249\n",
            "Epoch 19/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8284\n",
            "Epoch 20/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8286\n",
            "Epoch 21/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8312\n",
            "Epoch 22/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8341\n",
            "Epoch 23/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8346\n",
            "Epoch 24/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8356\n",
            "Epoch 25/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8367\n",
            "Epoch 26/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8389\n",
            "Epoch 27/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8386\n",
            "Epoch 28/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8402\n",
            "Epoch 29/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8399\n",
            "Epoch 30/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8427\n",
            "Epoch 31/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8416\n",
            "Epoch 32/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8429\n",
            "Epoch 33/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8440\n",
            "Epoch 34/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8429\n",
            "Epoch 35/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8457\n",
            "Epoch 36/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8470\n",
            "Epoch 37/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8459\n",
            "Epoch 38/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8468\n",
            "Epoch 39/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8498\n",
            "Epoch 40/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8489\n",
            "Epoch 41/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8494\n",
            "Epoch 42/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8515\n",
            "Epoch 43/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8496\n",
            "Epoch 44/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8526\n",
            "Epoch 45/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8513\n",
            "Epoch 46/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8521\n",
            "Epoch 47/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8522\n",
            "Epoch 48/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8526\n",
            "Epoch 49/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8519\n",
            "Epoch 50/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8536\n",
            "Epoch 51/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8536\n",
            "Epoch 52/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8539\n",
            "Epoch 53/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8534\n",
            "Epoch 54/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8539\n",
            "Epoch 55/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8543\n",
            "Epoch 56/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8549\n",
            "Epoch 57/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8549\n",
            "Epoch 58/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8547\n",
            "Epoch 59/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8552\n",
            "Epoch 60/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8551\n",
            "Epoch 61/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8545\n",
            "Epoch 62/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8562\n",
            "Epoch 63/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8552\n",
            "Epoch 64/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8552\n",
            "Epoch 65/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8567\n",
            "Epoch 66/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8556\n",
            "Epoch 67/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8560\n",
            "Epoch 68/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8562\n",
            "Epoch 69/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8560\n",
            "Epoch 70/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3464 - accuracy: 0.8551\n",
            "Epoch 71/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8571\n",
            "Epoch 72/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8552\n",
            "Epoch 73/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8567\n",
            "Epoch 74/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3457 - accuracy: 0.8573\n",
            "Epoch 75/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8558\n",
            "Epoch 76/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8545\n",
            "Epoch 77/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8573\n",
            "Epoch 78/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8554\n",
            "Epoch 79/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8558\n",
            "Epoch 80/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8560\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "42/42 [==============================] - 2s 5ms/step - loss: 0.7053 - accuracy: 0.5554\n",
            "Epoch 2/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6580\n",
            "Epoch 3/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7444\n",
            "Epoch 4/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7898\n",
            "Epoch 5/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.8039\n",
            "Epoch 6/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8059\n",
            "Epoch 7/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8082\n",
            "Epoch 8/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8089\n",
            "Epoch 9/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8110\n",
            "Epoch 10/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8127\n",
            "Epoch 11/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8140\n",
            "Epoch 12/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8151\n",
            "Epoch 13/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8159\n",
            "Epoch 14/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8153\n",
            "Epoch 15/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8162\n",
            "Epoch 16/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8176\n",
            "Epoch 17/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8183\n",
            "Epoch 18/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8209\n",
            "Epoch 19/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8209\n",
            "Epoch 20/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8226\n",
            "Epoch 21/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8236\n",
            "Epoch 22/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8271\n",
            "Epoch 23/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8286\n",
            "Epoch 24/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8305\n",
            "Epoch 25/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8324\n",
            "Epoch 26/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8352\n",
            "Epoch 27/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8382\n",
            "Epoch 28/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8408\n",
            "Epoch 29/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8414\n",
            "Epoch 30/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8432\n",
            "Epoch 31/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8446\n",
            "Epoch 32/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8462\n",
            "Epoch 33/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8453\n",
            "Epoch 34/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8487\n",
            "Epoch 35/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8476\n",
            "Epoch 36/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8489\n",
            "Epoch 37/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8506\n",
            "Epoch 38/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8511\n",
            "Epoch 39/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8507\n",
            "Epoch 40/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8526\n",
            "Epoch 41/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8532\n",
            "Epoch 42/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8528\n",
            "Epoch 43/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8530\n",
            "Epoch 44/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8534\n",
            "Epoch 45/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8541\n",
            "Epoch 46/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8541\n",
            "Epoch 47/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.8532\n",
            "Epoch 48/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8530\n",
            "Epoch 49/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8547\n",
            "Epoch 50/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8530\n",
            "Epoch 51/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8537\n",
            "Epoch 52/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8549\n",
            "Epoch 53/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8551\n",
            "Epoch 54/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8537\n",
            "Epoch 55/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8551\n",
            "Epoch 56/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8539\n",
            "Epoch 57/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8539\n",
            "Epoch 58/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8547\n",
            "Epoch 59/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8556\n",
            "Epoch 60/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8566\n",
            "Epoch 61/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8541\n",
            "Epoch 62/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8547\n",
            "Epoch 63/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3480 - accuracy: 0.8552\n",
            "Epoch 64/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8554\n",
            "Epoch 65/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8547\n",
            "Epoch 66/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8552\n",
            "Epoch 67/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8554\n",
            "Epoch 68/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8564\n",
            "Epoch 69/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8558\n",
            "Epoch 70/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8554\n",
            "Epoch 71/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8564\n",
            "Epoch 72/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8556\n",
            "Epoch 73/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8560\n",
            "Epoch 74/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8541\n",
            "Epoch 75/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8560\n",
            "Epoch 76/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8569\n",
            "Epoch 77/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8545\n",
            "Epoch 78/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8554\n",
            "Epoch 79/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8560\n",
            "Epoch 80/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8564\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/80\n",
            "42/42 [==============================] - 2s 5ms/step - loss: 0.6620 - accuracy: 0.5984\n",
            "Epoch 2/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7531\n",
            "Epoch 3/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7955\n",
            "Epoch 4/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8050\n",
            "Epoch 5/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8086\n",
            "Epoch 6/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8112\n",
            "Epoch 7/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8153\n",
            "Epoch 8/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8163\n",
            "Epoch 9/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8204\n",
            "Epoch 10/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8234\n",
            "Epoch 11/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8241\n",
            "Epoch 12/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8277\n",
            "Epoch 13/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8307\n",
            "Epoch 14/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8335\n",
            "Epoch 15/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8356\n",
            "Epoch 16/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8390\n",
            "Epoch 17/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8421\n",
            "Epoch 18/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8435\n",
            "Epoch 19/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8450\n",
            "Epoch 20/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8480\n",
            "Epoch 21/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8504\n",
            "Epoch 22/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8525\n",
            "Epoch 23/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8532\n",
            "Epoch 24/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8528\n",
            "Epoch 25/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8547\n",
            "Epoch 26/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8555\n",
            "Epoch 27/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8575\n",
            "Epoch 28/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8564\n",
            "Epoch 29/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8571\n",
            "Epoch 30/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8575\n",
            "Epoch 31/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8575\n",
            "Epoch 32/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8590\n",
            "Epoch 33/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8600\n",
            "Epoch 34/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8590\n",
            "Epoch 35/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8598\n",
            "Epoch 36/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8588\n",
            "Epoch 37/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8611\n",
            "Epoch 38/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8613\n",
            "Epoch 39/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8605\n",
            "Epoch 40/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8611\n",
            "Epoch 41/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8620\n",
            "Epoch 42/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8616\n",
            "Epoch 43/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8622\n",
            "Epoch 44/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8626\n",
            "Epoch 45/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8624\n",
            "Epoch 46/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8615\n",
            "Epoch 47/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8626\n",
            "Epoch 48/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8637\n",
            "Epoch 49/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8622\n",
            "Epoch 50/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8622\n",
            "Epoch 51/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8618\n",
            "Epoch 52/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8631\n",
            "Epoch 53/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8631\n",
            "Epoch 54/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8630\n",
            "Epoch 55/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8624\n",
            "Epoch 56/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8626\n",
            "Epoch 57/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8635\n",
            "Epoch 58/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8637\n",
            "Epoch 59/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8637\n",
            "Epoch 60/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8645\n",
            "Epoch 61/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8622\n",
            "Epoch 62/80\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8622\n",
            "Epoch 63/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8630\n",
            "Epoch 64/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8645\n",
            "Epoch 65/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3383 - accuracy: 0.8624\n",
            "Epoch 66/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8622\n",
            "Epoch 67/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8624\n",
            "Epoch 68/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8620\n",
            "Epoch 69/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8641\n",
            "Epoch 70/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8639\n",
            "Epoch 71/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8631\n",
            "Epoch 72/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8626\n",
            "Epoch 73/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8616\n",
            "Epoch 74/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8648\n",
            "Epoch 75/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8633\n",
            "Epoch 76/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8633\n",
            "Epoch 77/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8635\n",
            "Epoch 78/80\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.8658\n",
            "Epoch 79/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8631\n",
            "Epoch 80/80\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8615\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/107\n",
            "59/59 [==============================] - 2s 5ms/step - loss: 0.5728 - accuracy: 0.7289\n",
            "Epoch 2/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8011\n",
            "Epoch 3/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8071\n",
            "Epoch 4/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8078\n",
            "Epoch 5/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8119\n",
            "Epoch 6/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8149\n",
            "Epoch 7/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8219\n",
            "Epoch 8/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8234\n",
            "Epoch 9/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8305\n",
            "Epoch 10/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8350\n",
            "Epoch 11/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8365\n",
            "Epoch 12/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8410\n",
            "Epoch 13/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8446\n",
            "Epoch 14/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8481\n",
            "Epoch 15/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8492\n",
            "Epoch 16/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8492\n",
            "Epoch 17/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8506\n",
            "Epoch 18/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8522\n",
            "Epoch 19/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8528\n",
            "Epoch 20/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8528\n",
            "Epoch 21/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8549\n",
            "Epoch 22/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8532\n",
            "Epoch 23/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8577\n",
            "Epoch 24/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8562\n",
            "Epoch 25/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8562\n",
            "Epoch 26/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8577\n",
            "Epoch 27/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8592\n",
            "Epoch 28/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8581\n",
            "Epoch 29/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8597\n",
            "Epoch 30/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8582\n",
            "Epoch 31/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8582\n",
            "Epoch 32/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8597\n",
            "Epoch 33/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8564\n",
            "Epoch 34/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8597\n",
            "Epoch 35/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8596\n",
            "Epoch 36/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8594\n",
            "Epoch 37/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8599\n",
            "Epoch 38/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8605\n",
            "Epoch 39/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8626\n",
            "Epoch 40/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8597\n",
            "Epoch 41/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8622\n",
            "Epoch 42/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8609\n",
            "Epoch 43/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8611\n",
            "Epoch 44/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8614\n",
            "Epoch 45/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8612\n",
            "Epoch 46/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8635\n",
            "Epoch 47/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 48/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8620\n",
            "Epoch 49/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8618\n",
            "Epoch 50/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 51/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8624\n",
            "Epoch 52/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8614\n",
            "Epoch 53/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8646\n",
            "Epoch 54/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8629\n",
            "Epoch 55/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8631\n",
            "Epoch 56/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8637\n",
            "Epoch 57/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8642\n",
            "Epoch 58/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8642\n",
            "Epoch 59/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8635\n",
            "Epoch 60/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8637\n",
            "Epoch 61/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8633\n",
            "Epoch 62/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8635\n",
            "Epoch 63/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8656\n",
            "Epoch 64/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8680\n",
            "Epoch 65/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8671\n",
            "Epoch 66/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8657\n",
            "Epoch 67/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8650\n",
            "Epoch 68/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8648\n",
            "Epoch 69/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8637\n",
            "Epoch 70/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8671\n",
            "Epoch 71/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8644\n",
            "Epoch 72/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8657\n",
            "Epoch 73/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8674\n",
            "Epoch 74/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8661\n",
            "Epoch 75/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8665\n",
            "Epoch 76/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8656\n",
            "Epoch 77/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8633\n",
            "Epoch 78/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8665\n",
            "Epoch 79/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3143 - accuracy: 0.8667\n",
            "Epoch 80/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8646\n",
            "Epoch 81/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8671\n",
            "Epoch 82/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8657\n",
            "Epoch 83/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8652\n",
            "Epoch 84/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8691\n",
            "Epoch 85/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.8648\n",
            "Epoch 86/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8672\n",
            "Epoch 87/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8657\n",
            "Epoch 88/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8686\n",
            "Epoch 89/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3113 - accuracy: 0.8672\n",
            "Epoch 90/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.8678\n",
            "Epoch 91/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3102 - accuracy: 0.8671\n",
            "Epoch 92/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8693\n",
            "Epoch 93/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8686\n",
            "Epoch 94/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8716\n",
            "Epoch 95/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8661\n",
            "Epoch 96/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.8689\n",
            "Epoch 97/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8654\n",
            "Epoch 98/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8684\n",
            "Epoch 99/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8684\n",
            "Epoch 100/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8708\n",
            "Epoch 101/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8689\n",
            "Epoch 102/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8680\n",
            "Epoch 103/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8704\n",
            "Epoch 104/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8686\n",
            "Epoch 105/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8695\n",
            "Epoch 106/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8699\n",
            "Epoch 107/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8704\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/107\n",
            "59/59 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.6972\n",
            "Epoch 2/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7962\n",
            "Epoch 3/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8091\n",
            "Epoch 4/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8110\n",
            "Epoch 5/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8181\n",
            "Epoch 6/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8204\n",
            "Epoch 7/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8241\n",
            "Epoch 8/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8314\n",
            "Epoch 9/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8339\n",
            "Epoch 10/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8397\n",
            "Epoch 11/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8429\n",
            "Epoch 12/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8453\n",
            "Epoch 13/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8502\n",
            "Epoch 14/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8509\n",
            "Epoch 15/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8504\n",
            "Epoch 16/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8545\n",
            "Epoch 17/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8556\n",
            "Epoch 18/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8571\n",
            "Epoch 19/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8562\n",
            "Epoch 20/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8577\n",
            "Epoch 21/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8569\n",
            "Epoch 22/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8562\n",
            "Epoch 23/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8573\n",
            "Epoch 24/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8552\n",
            "Epoch 25/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8596\n",
            "Epoch 26/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8597\n",
            "Epoch 27/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3462 - accuracy: 0.8569\n",
            "Epoch 28/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8577\n",
            "Epoch 29/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8566\n",
            "Epoch 30/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3435 - accuracy: 0.8586\n",
            "Epoch 31/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8566\n",
            "Epoch 32/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8601\n",
            "Epoch 33/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8609\n",
            "Epoch 34/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8599\n",
            "Epoch 35/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8590\n",
            "Epoch 36/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8579\n",
            "Epoch 37/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8624\n",
            "Epoch 38/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8611\n",
            "Epoch 39/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8597\n",
            "Epoch 40/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8627\n",
            "Epoch 41/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8605\n",
            "Epoch 42/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8639\n",
            "Epoch 43/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8611\n",
            "Epoch 44/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8641\n",
            "Epoch 45/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8642\n",
            "Epoch 46/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8641\n",
            "Epoch 47/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8657\n",
            "Epoch 48/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8648\n",
            "Epoch 49/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 50/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8627\n",
            "Epoch 51/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 52/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8627\n",
            "Epoch 53/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8650\n",
            "Epoch 54/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8661\n",
            "Epoch 55/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8641\n",
            "Epoch 56/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8656\n",
            "Epoch 57/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8665\n",
            "Epoch 58/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8641\n",
            "Epoch 59/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8661\n",
            "Epoch 60/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8659\n",
            "Epoch 61/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8678\n",
            "Epoch 62/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8644\n",
            "Epoch 63/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8676\n",
            "Epoch 64/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8663\n",
            "Epoch 65/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8652\n",
            "Epoch 66/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8657\n",
            "Epoch 67/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8648\n",
            "Epoch 68/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8654\n",
            "Epoch 69/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8676\n",
            "Epoch 70/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8678\n",
            "Epoch 71/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8674\n",
            "Epoch 72/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8671\n",
            "Epoch 73/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8676\n",
            "Epoch 74/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8669\n",
            "Epoch 75/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8663\n",
            "Epoch 76/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8663\n",
            "Epoch 77/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3177 - accuracy: 0.8693\n",
            "Epoch 78/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8676\n",
            "Epoch 79/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8702\n",
            "Epoch 80/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8674\n",
            "Epoch 81/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8669\n",
            "Epoch 82/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3168 - accuracy: 0.8672\n",
            "Epoch 83/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8684\n",
            "Epoch 84/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8695\n",
            "Epoch 85/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8678\n",
            "Epoch 86/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8678\n",
            "Epoch 87/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3147 - accuracy: 0.8686\n",
            "Epoch 88/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8699\n",
            "Epoch 89/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8701\n",
            "Epoch 90/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8676\n",
            "Epoch 91/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8697\n",
            "Epoch 92/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8699\n",
            "Epoch 93/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8701\n",
            "Epoch 94/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8699\n",
            "Epoch 95/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8701\n",
            "Epoch 96/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8689\n",
            "Epoch 97/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8695\n",
            "Epoch 98/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8701\n",
            "Epoch 99/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8684\n",
            "Epoch 100/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8680\n",
            "Epoch 101/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8699\n",
            "Epoch 102/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8701\n",
            "Epoch 103/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8699\n",
            "Epoch 104/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8704\n",
            "Epoch 105/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8706\n",
            "Epoch 106/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8721\n",
            "Epoch 107/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8689\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/107\n",
            "59/59 [==============================] - 1s 5ms/step - loss: 0.5955 - accuracy: 0.7075\n",
            "Epoch 2/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7966\n",
            "Epoch 3/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8082\n",
            "Epoch 4/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8112\n",
            "Epoch 5/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8165\n",
            "Epoch 6/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8183\n",
            "Epoch 7/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8358\n",
            "Epoch 8/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8382\n",
            "Epoch 9/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8448\n",
            "Epoch 10/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8476\n",
            "Epoch 11/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8526\n",
            "Epoch 12/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8534\n",
            "Epoch 13/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8556\n",
            "Epoch 14/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8571\n",
            "Epoch 15/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8588\n",
            "Epoch 16/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8570\n",
            "Epoch 17/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8611\n",
            "Epoch 18/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8586\n",
            "Epoch 19/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8609\n",
            "Epoch 20/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3471 - accuracy: 0.8615\n",
            "Epoch 21/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8609\n",
            "Epoch 22/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8605\n",
            "Epoch 23/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8615\n",
            "Epoch 24/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8615\n",
            "Epoch 25/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8603\n",
            "Epoch 26/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8622\n",
            "Epoch 27/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8624\n",
            "Epoch 28/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8609\n",
            "Epoch 29/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8601\n",
            "Epoch 30/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8620\n",
            "Epoch 31/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8603\n",
            "Epoch 32/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8611\n",
            "Epoch 33/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8652\n",
            "Epoch 34/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8645\n",
            "Epoch 35/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8635\n",
            "Epoch 36/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8637\n",
            "Epoch 37/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8633\n",
            "Epoch 38/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8665\n",
            "Epoch 39/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8660\n",
            "Epoch 40/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8637\n",
            "Epoch 41/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8665\n",
            "Epoch 42/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8665\n",
            "Epoch 43/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8684\n",
            "Epoch 44/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8650\n",
            "Epoch 45/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 46/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8671\n",
            "Epoch 47/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8703\n",
            "Epoch 48/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8688\n",
            "Epoch 49/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8690\n",
            "Epoch 50/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8693\n",
            "Epoch 51/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8697\n",
            "Epoch 52/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8706\n",
            "Epoch 53/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8688\n",
            "Epoch 54/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8697\n",
            "Epoch 55/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8703\n",
            "Epoch 56/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3204 - accuracy: 0.8701\n",
            "Epoch 57/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8716\n",
            "Epoch 58/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8708\n",
            "Epoch 59/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8706\n",
            "Epoch 60/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8706\n",
            "Epoch 61/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8723\n",
            "Epoch 62/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8690\n",
            "Epoch 63/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8708\n",
            "Epoch 64/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8703\n",
            "Epoch 65/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8712\n",
            "Epoch 66/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8720\n",
            "Epoch 67/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.8706\n",
            "Epoch 68/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3143 - accuracy: 0.8712\n",
            "Epoch 69/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3141 - accuracy: 0.8731\n",
            "Epoch 70/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3133 - accuracy: 0.8720\n",
            "Epoch 71/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8716\n",
            "Epoch 72/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8740\n",
            "Epoch 73/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8718\n",
            "Epoch 74/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8718\n",
            "Epoch 75/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8723\n",
            "Epoch 76/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8729\n",
            "Epoch 77/107\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.3105 - accuracy: 0.8746\n",
            "Epoch 78/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3105 - accuracy: 0.8746\n",
            "Epoch 79/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8738\n",
            "Epoch 80/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8740\n",
            "Epoch 81/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8716\n",
            "Epoch 82/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8729\n",
            "Epoch 83/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8733\n",
            "Epoch 84/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8729\n",
            "Epoch 85/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8738\n",
            "Epoch 86/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8727\n",
            "Epoch 87/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8744\n",
            "Epoch 88/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8761\n",
            "Epoch 89/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8748\n",
            "Epoch 90/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8785\n",
            "Epoch 91/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8783\n",
            "Epoch 92/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8731\n",
            "Epoch 93/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8740\n",
            "Epoch 94/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8761\n",
            "Epoch 95/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8759\n",
            "Epoch 96/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8746\n",
            "Epoch 97/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8768\n",
            "Epoch 98/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8736\n",
            "Epoch 99/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8757\n",
            "Epoch 100/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8736\n",
            "Epoch 101/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8763\n",
            "Epoch 102/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8753\n",
            "Epoch 103/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8766\n",
            "Epoch 104/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8766\n",
            "Epoch 105/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8755\n",
            "Epoch 106/107\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8778\n",
            "Epoch 107/107\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8783\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/52\n",
            "47/47 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5762\n",
            "Epoch 2/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7643\n",
            "Epoch 3/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7943\n",
            "Epoch 4/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8029\n",
            "Epoch 5/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8057\n",
            "Epoch 6/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8102\n",
            "Epoch 7/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8121\n",
            "Epoch 8/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8157\n",
            "Epoch 9/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8185\n",
            "Epoch 10/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8209\n",
            "Epoch 11/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8256\n",
            "Epoch 12/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8282\n",
            "Epoch 13/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8339\n",
            "Epoch 14/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8371\n",
            "Epoch 15/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8402\n",
            "Epoch 16/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8438\n",
            "Epoch 17/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8446\n",
            "Epoch 18/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8477\n",
            "Epoch 19/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8494\n",
            "Epoch 20/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8500\n",
            "Epoch 21/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8509\n",
            "Epoch 22/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8519\n",
            "Epoch 23/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8522\n",
            "Epoch 24/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8534\n",
            "Epoch 25/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8556\n",
            "Epoch 26/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8539\n",
            "Epoch 27/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8560\n",
            "Epoch 28/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8560\n",
            "Epoch 29/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8552\n",
            "Epoch 30/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8560\n",
            "Epoch 31/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8566\n",
            "Epoch 32/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8571\n",
            "Epoch 33/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8586\n",
            "Epoch 34/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8582\n",
            "Epoch 35/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8562\n",
            "Epoch 36/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8581\n",
            "Epoch 37/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8596\n",
            "Epoch 38/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8596\n",
            "Epoch 39/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8594\n",
            "Epoch 40/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8590\n",
            "Epoch 41/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8594\n",
            "Epoch 42/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8594\n",
            "Epoch 43/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8624\n",
            "Epoch 44/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8603\n",
            "Epoch 45/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8592\n",
            "Epoch 46/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8594\n",
            "Epoch 47/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8601\n",
            "Epoch 48/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8614\n",
            "Epoch 49/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8611\n",
            "Epoch 50/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8601\n",
            "Epoch 51/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8629\n",
            "Epoch 52/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8599\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/52\n",
            "47/47 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.6574\n",
            "Epoch 2/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7690\n",
            "Epoch 3/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.8003\n",
            "Epoch 4/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8056\n",
            "Epoch 5/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8074\n",
            "Epoch 6/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8138\n",
            "Epoch 7/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8189\n",
            "Epoch 8/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8209\n",
            "Epoch 9/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8222\n",
            "Epoch 10/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8258\n",
            "Epoch 11/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8282\n",
            "Epoch 12/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8322\n",
            "Epoch 13/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8333\n",
            "Epoch 14/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8369\n",
            "Epoch 15/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8382\n",
            "Epoch 16/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8421\n",
            "Epoch 17/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8449\n",
            "Epoch 18/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8446\n",
            "Epoch 19/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8466\n",
            "Epoch 20/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8489\n",
            "Epoch 21/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8498\n",
            "Epoch 22/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8500\n",
            "Epoch 23/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8504\n",
            "Epoch 24/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8522\n",
            "Epoch 25/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8537\n",
            "Epoch 26/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8547\n",
            "Epoch 27/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8547\n",
            "Epoch 28/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.8571\n",
            "Epoch 29/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8573\n",
            "Epoch 30/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3521 - accuracy: 0.8537\n",
            "Epoch 31/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8571\n",
            "Epoch 32/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8579\n",
            "Epoch 33/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8579\n",
            "Epoch 34/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8558\n",
            "Epoch 35/52\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8571\n",
            "Epoch 36/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8577\n",
            "Epoch 37/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8581\n",
            "Epoch 38/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8575\n",
            "Epoch 39/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8564\n",
            "Epoch 40/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8577\n",
            "Epoch 41/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8594\n",
            "Epoch 42/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8575\n",
            "Epoch 43/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8571\n",
            "Epoch 44/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8577\n",
            "Epoch 45/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8584\n",
            "Epoch 46/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8607\n",
            "Epoch 47/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8579\n",
            "Epoch 48/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8590\n",
            "Epoch 49/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8590\n",
            "Epoch 50/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8592\n",
            "Epoch 51/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8592\n",
            "Epoch 52/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8596\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/52\n",
            "47/47 [==============================] - 2s 5ms/step - loss: 0.6456 - accuracy: 0.6654\n",
            "Epoch 2/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7882\n",
            "Epoch 3/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.8080\n",
            "Epoch 4/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.8112\n",
            "Epoch 5/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8140\n",
            "Epoch 6/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8155\n",
            "Epoch 7/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8206\n",
            "Epoch 8/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8245\n",
            "Epoch 9/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8290\n",
            "Epoch 10/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8313\n",
            "Epoch 11/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8339\n",
            "Epoch 12/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8369\n",
            "Epoch 13/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8399\n",
            "Epoch 14/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8438\n",
            "Epoch 15/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8459\n",
            "Epoch 16/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8483\n",
            "Epoch 17/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8513\n",
            "Epoch 18/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8513\n",
            "Epoch 19/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.8538\n",
            "Epoch 20/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8530\n",
            "Epoch 21/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8551\n",
            "Epoch 22/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8556\n",
            "Epoch 23/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8562\n",
            "Epoch 24/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8581\n",
            "Epoch 25/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8583\n",
            "Epoch 26/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8583\n",
            "Epoch 27/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8581\n",
            "Epoch 28/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8613\n",
            "Epoch 29/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8590\n",
            "Epoch 30/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8590\n",
            "Epoch 31/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8615\n",
            "Epoch 32/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8613\n",
            "Epoch 33/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8598\n",
            "Epoch 34/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8613\n",
            "Epoch 35/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8609\n",
            "Epoch 36/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8577\n",
            "Epoch 37/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8615\n",
            "Epoch 38/52\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8605\n",
            "Epoch 39/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8600\n",
            "Epoch 40/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8615\n",
            "Epoch 41/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8615\n",
            "Epoch 42/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8616\n",
            "Epoch 43/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8611\n",
            "Epoch 44/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8607\n",
            "Epoch 45/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8613\n",
            "Epoch 46/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8620\n",
            "Epoch 47/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8618\n",
            "Epoch 48/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8601\n",
            "Epoch 49/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8622\n",
            "Epoch 50/52\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8630\n",
            "Epoch 51/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8652\n",
            "Epoch 52/52\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8628\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/67\n",
            "50/50 [==============================] - 2s 5ms/step - loss: 0.6304 - accuracy: 0.6782\n",
            "Epoch 2/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7712\n",
            "Epoch 3/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7984\n",
            "Epoch 4/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8044\n",
            "Epoch 5/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.8095\n",
            "Epoch 6/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.8106\n",
            "Epoch 7/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8146\n",
            "Epoch 8/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8153\n",
            "Epoch 9/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8183\n",
            "Epoch 10/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8191\n",
            "Epoch 11/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8207\n",
            "Epoch 12/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8230\n",
            "Epoch 13/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8245\n",
            "Epoch 14/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8254\n",
            "Epoch 15/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8279\n",
            "Epoch 16/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8316\n",
            "Epoch 17/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8322\n",
            "Epoch 18/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8346\n",
            "Epoch 19/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8365\n",
            "Epoch 20/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8389\n",
            "Epoch 21/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8408\n",
            "Epoch 22/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8423\n",
            "Epoch 23/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8442\n",
            "Epoch 24/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8447\n",
            "Epoch 25/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8455\n",
            "Epoch 26/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8466\n",
            "Epoch 27/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8461\n",
            "Epoch 28/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8457\n",
            "Epoch 29/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8466\n",
            "Epoch 30/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8481\n",
            "Epoch 31/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8479\n",
            "Epoch 32/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8474\n",
            "Epoch 33/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8502\n",
            "Epoch 34/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8494\n",
            "Epoch 35/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8507\n",
            "Epoch 36/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8507\n",
            "Epoch 37/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8511\n",
            "Epoch 38/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8515\n",
            "Epoch 39/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8522\n",
            "Epoch 40/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8526\n",
            "Epoch 41/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8521\n",
            "Epoch 42/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8530\n",
            "Epoch 43/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8537\n",
            "Epoch 44/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8537\n",
            "Epoch 45/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8536\n",
            "Epoch 46/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8530\n",
            "Epoch 47/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8541\n",
            "Epoch 48/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3440 - accuracy: 0.8543\n",
            "Epoch 49/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8541\n",
            "Epoch 50/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8536\n",
            "Epoch 51/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8554\n",
            "Epoch 52/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8562\n",
            "Epoch 53/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8536\n",
            "Epoch 54/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8551\n",
            "Epoch 55/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8545\n",
            "Epoch 56/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8558\n",
            "Epoch 57/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8551\n",
            "Epoch 58/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8551\n",
            "Epoch 59/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8554\n",
            "Epoch 60/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8537\n",
            "Epoch 61/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8564\n",
            "Epoch 62/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8575\n",
            "Epoch 63/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8560\n",
            "Epoch 64/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8566\n",
            "Epoch 65/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8562\n",
            "Epoch 66/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8564\n",
            "Epoch 67/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8560\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/67\n",
            "50/50 [==============================] - 2s 5ms/step - loss: 0.7208 - accuracy: 0.5089\n",
            "Epoch 2/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7403\n",
            "Epoch 3/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7860\n",
            "Epoch 4/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7964\n",
            "Epoch 5/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8044\n",
            "Epoch 6/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8112\n",
            "Epoch 7/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8144\n",
            "Epoch 8/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8168\n",
            "Epoch 9/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8200\n",
            "Epoch 10/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8221\n",
            "Epoch 11/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8254\n",
            "Epoch 12/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8264\n",
            "Epoch 13/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8296\n",
            "Epoch 14/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8305\n",
            "Epoch 15/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8335\n",
            "Epoch 16/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8352\n",
            "Epoch 17/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8372\n",
            "Epoch 18/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8404\n",
            "Epoch 19/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8419\n",
            "Epoch 20/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8436\n",
            "Epoch 21/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8462\n",
            "Epoch 22/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8474\n",
            "Epoch 23/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8466\n",
            "Epoch 24/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8489\n",
            "Epoch 25/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8513\n",
            "Epoch 26/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8526\n",
            "Epoch 27/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8537\n",
            "Epoch 28/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8532\n",
            "Epoch 29/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8530\n",
            "Epoch 30/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8558\n",
            "Epoch 31/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3573 - accuracy: 0.8558\n",
            "Epoch 32/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8549\n",
            "Epoch 33/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8562\n",
            "Epoch 34/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8562\n",
            "Epoch 35/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8566\n",
            "Epoch 36/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8584\n",
            "Epoch 37/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8582\n",
            "Epoch 38/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8586\n",
            "Epoch 39/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8581\n",
            "Epoch 40/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8586\n",
            "Epoch 41/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8577\n",
            "Epoch 42/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8584\n",
            "Epoch 43/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8579\n",
            "Epoch 44/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8596\n",
            "Epoch 45/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8582\n",
            "Epoch 46/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8599\n",
            "Epoch 47/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8581\n",
            "Epoch 48/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8586\n",
            "Epoch 49/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8597\n",
            "Epoch 50/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8588\n",
            "Epoch 51/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3471 - accuracy: 0.8594\n",
            "Epoch 52/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8569\n",
            "Epoch 53/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8597\n",
            "Epoch 54/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8592\n",
            "Epoch 55/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8586\n",
            "Epoch 56/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8596\n",
            "Epoch 57/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8594\n",
            "Epoch 58/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8596\n",
            "Epoch 59/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8586\n",
            "Epoch 60/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8597\n",
            "Epoch 61/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8586\n",
            "Epoch 62/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8575\n",
            "Epoch 63/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8590\n",
            "Epoch 64/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8584\n",
            "Epoch 65/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8605\n",
            "Epoch 66/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8596\n",
            "Epoch 67/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8603\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/67\n",
            "50/50 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7870\n",
            "Epoch 2/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7962\n",
            "Epoch 3/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7960\n",
            "Epoch 4/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7972\n",
            "Epoch 5/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8028\n",
            "Epoch 6/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8153\n",
            "Epoch 7/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8262\n",
            "Epoch 8/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8348\n",
            "Epoch 9/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8410\n",
            "Epoch 10/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8412\n",
            "Epoch 11/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8433\n",
            "Epoch 12/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8461\n",
            "Epoch 13/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8468\n",
            "Epoch 14/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8496\n",
            "Epoch 15/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8502\n",
            "Epoch 16/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8526\n",
            "Epoch 17/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8528\n",
            "Epoch 18/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8540\n",
            "Epoch 19/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8551\n",
            "Epoch 20/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8566\n",
            "Epoch 21/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8562\n",
            "Epoch 22/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8575\n",
            "Epoch 23/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8577\n",
            "Epoch 24/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8586\n",
            "Epoch 25/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8583\n",
            "Epoch 26/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8575\n",
            "Epoch 27/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8579\n",
            "Epoch 28/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8581\n",
            "Epoch 29/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8594\n",
            "Epoch 30/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8583\n",
            "Epoch 31/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8596\n",
            "Epoch 32/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8581\n",
            "Epoch 33/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8594\n",
            "Epoch 34/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8590\n",
            "Epoch 35/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8585\n",
            "Epoch 36/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8603\n",
            "Epoch 37/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8586\n",
            "Epoch 38/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8588\n",
            "Epoch 39/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8583\n",
            "Epoch 40/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8598\n",
            "Epoch 41/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8586\n",
            "Epoch 42/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8592\n",
            "Epoch 43/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8596\n",
            "Epoch 44/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8607\n",
            "Epoch 45/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8611\n",
            "Epoch 46/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8601\n",
            "Epoch 47/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8605\n",
            "Epoch 48/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8600\n",
            "Epoch 49/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8613\n",
            "Epoch 50/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8611\n",
            "Epoch 51/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8613\n",
            "Epoch 52/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3310 - accuracy: 0.8616\n",
            "Epoch 53/67\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 54/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8624\n",
            "Epoch 55/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8618\n",
            "Epoch 56/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8620\n",
            "Epoch 57/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8626\n",
            "Epoch 58/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8620\n",
            "Epoch 59/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8630\n",
            "Epoch 60/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8618\n",
            "Epoch 61/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8630\n",
            "Epoch 62/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8630\n",
            "Epoch 63/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8633\n",
            "Epoch 64/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 65/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8630\n",
            "Epoch 66/67\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8615\n",
            "Epoch 67/67\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8616\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Epoch 1/52\n",
            "70/70 [==============================] - 2s 5ms/step - loss: 0.6031 - accuracy: 0.6834\n",
            "Epoch 2/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7950\n",
            "Epoch 3/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8085\n",
            "Epoch 4/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8131\n",
            "Epoch 5/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8155\n",
            "Epoch 6/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8192\n",
            "Epoch 7/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8278\n",
            "Epoch 8/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8342\n",
            "Epoch 9/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8382\n",
            "Epoch 10/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8446\n",
            "Epoch 11/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8474\n",
            "Epoch 12/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8504\n",
            "Epoch 13/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8514\n",
            "Epoch 14/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8528\n",
            "Epoch 15/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8543\n",
            "Epoch 16/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8544\n",
            "Epoch 17/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8544\n",
            "Epoch 18/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8553\n",
            "Epoch 19/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8555\n",
            "Epoch 20/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8551\n",
            "Epoch 21/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8560\n",
            "Epoch 22/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8569\n",
            "Epoch 23/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8569\n",
            "Epoch 24/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8562\n",
            "Epoch 25/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8570\n",
            "Epoch 26/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8587\n",
            "Epoch 27/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8586\n",
            "Epoch 28/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8569\n",
            "Epoch 29/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8575\n",
            "Epoch 30/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8575\n",
            "Epoch 31/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8601\n",
            "Epoch 32/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8587\n",
            "Epoch 33/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8589\n",
            "Epoch 34/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8604\n",
            "Epoch 35/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8594\n",
            "Epoch 36/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8586\n",
            "Epoch 37/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8594\n",
            "Epoch 38/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8593\n",
            "Epoch 39/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8600\n",
            "Epoch 40/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8606\n",
            "Epoch 41/52\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8590\n",
            "Epoch 42/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8587\n",
            "Epoch 43/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8601\n",
            "Epoch 44/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8602\n",
            "Epoch 45/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8602\n",
            "Epoch 46/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8614\n",
            "Epoch 47/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8601\n",
            "Epoch 48/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8595\n",
            "Epoch 49/52\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8610\n",
            "Epoch 50/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8619\n",
            "Epoch 51/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8600\n",
            "Epoch 52/52\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8590\n",
            "Best Parameters: {'activation': 'tanh', 'batch_size': 115, 'epochs': 52, 'optimizer': 'adam', 'units': 18}\n",
            "Best Model: <keras.wrappers.scikit_learn.KerasClassifier object at 0x7eff685b9570>\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "def create_model(units=16, activation='relu', optimizer='adam'):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(units=units, activation=activation, input_dim=X_train_scaled.shape[1]))\n",
        "    model.add(keras.layers.Dense(units=units, activation=activation))\n",
        "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "param_dist = {\n",
        "    'units': sp_randint(8, 33),            # Number of units in hidden layers\n",
        "    'activation': ['relu', 'tanh'],        # Activation function\n",
        "    'optimizer': ['adam', 'rmsprop'],      # Optimization algorithm\n",
        "    'batch_size': sp_randint(32, 129),     # Batch size\n",
        "    'epochs': sp_randint(50, 201)          # Number of training epochs\n",
        "}\n",
        "\n",
        "# Create the model to tune\n",
        "model = keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model)\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform random search\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Model:\", best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDM1Sq8xWIOh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzIrLi_sWIQ-",
        "outputId": "175ebfc8-41a9-4cd7-fc18-560ab7b095b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 18)                198       \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 8)                 152       \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 359\n",
            "Trainable params: 359\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Initialize the ANN model\n",
        "new_model = keras.Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "new_model.add(keras.layers.Dense(units=18, activation='tanh', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "# Add additional hidden layers\n",
        "new_model.add(keras.layers.Dense(units=8, activation='tanh'))\n",
        "\n",
        "# Add output layer\n",
        "new_model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "new_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcEwODZbWIUu",
        "outputId": "2cbaefc4-2c86-4922-da5f-ab3d5ffa7ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "56/56 [==============================] - 2s 7ms/step - loss: 0.6369 - accuracy: 0.6472 - val_loss: 0.5616 - val_accuracy: 0.7425\n",
            "Epoch 2/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7752 - val_loss: 0.4739 - val_accuracy: 0.7987\n",
            "Epoch 3/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.8002 - val_loss: 0.4344 - val_accuracy: 0.8131\n",
            "Epoch 4/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8031 - val_loss: 0.4239 - val_accuracy: 0.8156\n",
            "Epoch 5/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8058 - val_loss: 0.4187 - val_accuracy: 0.8181\n",
            "Epoch 6/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8097 - val_loss: 0.4159 - val_accuracy: 0.8200\n",
            "Epoch 7/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8091 - val_loss: 0.4110 - val_accuracy: 0.8213\n",
            "Epoch 8/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8125 - val_loss: 0.4069 - val_accuracy: 0.8244\n",
            "Epoch 9/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8175 - val_loss: 0.4024 - val_accuracy: 0.8244\n",
            "Epoch 10/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8216 - val_loss: 0.3970 - val_accuracy: 0.8294\n",
            "Epoch 11/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8264 - val_loss: 0.3921 - val_accuracy: 0.8313\n",
            "Epoch 12/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8320 - val_loss: 0.3862 - val_accuracy: 0.8369\n",
            "Epoch 13/52\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8336 - val_loss: 0.3821 - val_accuracy: 0.8363\n",
            "Epoch 14/52\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8391 - val_loss: 0.3780 - val_accuracy: 0.8381\n",
            "Epoch 15/52\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8413 - val_loss: 0.3744 - val_accuracy: 0.8406\n",
            "Epoch 16/52\n",
            "56/56 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8445 - val_loss: 0.3714 - val_accuracy: 0.8419\n",
            "Epoch 17/52\n",
            "56/56 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8470 - val_loss: 0.3698 - val_accuracy: 0.8406\n",
            "Epoch 18/52\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8483 - val_loss: 0.3661 - val_accuracy: 0.8431\n",
            "Epoch 19/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8502 - val_loss: 0.3639 - val_accuracy: 0.8438\n",
            "Epoch 20/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8523 - val_loss: 0.3619 - val_accuracy: 0.8438\n",
            "Epoch 21/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8525 - val_loss: 0.3606 - val_accuracy: 0.8438\n",
            "Epoch 22/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8542 - val_loss: 0.3585 - val_accuracy: 0.8450\n",
            "Epoch 23/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8541 - val_loss: 0.3567 - val_accuracy: 0.8444\n",
            "Epoch 24/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8545 - val_loss: 0.3552 - val_accuracy: 0.8462\n",
            "Epoch 25/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8544 - val_loss: 0.3537 - val_accuracy: 0.8506\n",
            "Epoch 26/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8566 - val_loss: 0.3532 - val_accuracy: 0.8506\n",
            "Epoch 27/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8544 - val_loss: 0.3518 - val_accuracy: 0.8494\n",
            "Epoch 28/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8548 - val_loss: 0.3505 - val_accuracy: 0.8500\n",
            "Epoch 29/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8556 - val_loss: 0.3501 - val_accuracy: 0.8512\n",
            "Epoch 30/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8555 - val_loss: 0.3490 - val_accuracy: 0.8519\n",
            "Epoch 31/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8561 - val_loss: 0.3476 - val_accuracy: 0.8537\n",
            "Epoch 32/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8561 - val_loss: 0.3478 - val_accuracy: 0.8512\n",
            "Epoch 33/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8573 - val_loss: 0.3460 - val_accuracy: 0.8556\n",
            "Epoch 34/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8567 - val_loss: 0.3460 - val_accuracy: 0.8544\n",
            "Epoch 35/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8573 - val_loss: 0.3456 - val_accuracy: 0.8531\n",
            "Epoch 36/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8581 - val_loss: 0.3451 - val_accuracy: 0.8544\n",
            "Epoch 37/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8587 - val_loss: 0.3448 - val_accuracy: 0.8519\n",
            "Epoch 38/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8595 - val_loss: 0.3438 - val_accuracy: 0.8537\n",
            "Epoch 39/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8573 - val_loss: 0.3437 - val_accuracy: 0.8525\n",
            "Epoch 40/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8597 - val_loss: 0.3424 - val_accuracy: 0.8531\n",
            "Epoch 41/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8587 - val_loss: 0.3421 - val_accuracy: 0.8537\n",
            "Epoch 42/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8591 - val_loss: 0.3420 - val_accuracy: 0.8531\n",
            "Epoch 43/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8603 - val_loss: 0.3408 - val_accuracy: 0.8531\n",
            "Epoch 44/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8581 - val_loss: 0.3411 - val_accuracy: 0.8544\n",
            "Epoch 45/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8592 - val_loss: 0.3403 - val_accuracy: 0.8550\n",
            "Epoch 46/52\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8611 - val_loss: 0.3398 - val_accuracy: 0.8550\n",
            "Epoch 47/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8611 - val_loss: 0.3394 - val_accuracy: 0.8544\n",
            "Epoch 48/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8597 - val_loss: 0.3397 - val_accuracy: 0.8531\n",
            "Epoch 49/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8606 - val_loss: 0.3399 - val_accuracy: 0.8550\n",
            "Epoch 50/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8600 - val_loss: 0.3391 - val_accuracy: 0.8556\n",
            "Epoch 51/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8611 - val_loss: 0.3405 - val_accuracy: 0.8531\n",
            "Epoch 52/52\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8603 - val_loss: 0.3383 - val_accuracy: 0.8531\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8620\n",
            "Test Loss: 0.33498743176460266\n",
            "Test Accuracy: 0.8619999885559082\n"
          ]
        }
      ],
      "source": [
        "# Train the ANN model\n",
        "model_history = new_model.fit(X_train_scaled, y_train, batch_size=115, epochs=52, validation_split=0.2, callbacks = early_stopping)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "test_loss, test_accuracy = new_model.evaluate(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jtHbE6FTYApm"
      },
      "source": [
        "# Save trained Model with pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RI7Qe3KYYCkI"
      },
      "outputs": [],
      "source": [
        "### Create a Pickle file using serialization\n",
        "import pickle\n",
        "pickle_out = open(\"model.pkl\",\"wb\")\n",
        "pickle.dump(model, pickle_out)\n",
        "pickle_out.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
